{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Up: \n",
    "Before Running the cell below, you must ensure that these have been run in Terminal **IN ORDER** : \n",
    "- conda update -n base -c defaults conda \n",
    "\n",
    "    - cd SageMaker\n",
    "    \n",
    "      - cd yelp-dataset-challenge-1-ds\n",
    "      \n",
    "         - conda env create -f environment.yml\n",
    "          \n",
    "            - source activate ydc1 \n",
    "                \n",
    "                - pip install python-decouple\n",
    "                  \n",
    "                  - pip install pprintpp\n",
    "                  \n",
    "# Spacy Installs: \n",
    "\n",
    "   - python -m spacy download en_core_web_lg\n",
    "\n",
    "        - python -m spacy link en_core_web_lg en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['API/',\n",
       " 'API/api.py',\n",
       " 'API/api_exploration.ipynb',\n",
       " 'Environments/',\n",
       " 'Environments/environment.yml',\n",
       " 'Flask_App/',\n",
       " 'Flask_App/Pipfile',\n",
       " 'Flask_App/__init__.py',\n",
       " 'Flask_App/app.py',\n",
       " 'Flask_App/models.py',\n",
       " 'Flask_App/yelp.py',\n",
       " 'Model/',\n",
       " 'Model/vect_1.sav',\n",
       " 'datasets/',\n",
       " 'datasets/df.csv',\n",
       " 'datasets/dtm.csv',\n",
       " 'datasets/dtm_final.csv',\n",
       " 'datasets/user.json',\n",
       " 'notebooks/',\n",
       " 'notebooks/data_cleanup.ipynb',\n",
       " 'notebooks/official_NB.ipynb',\n",
       " 'notebooks/vectorization_exploration.ipynb',\n",
       " 'notebooks/yelp_data_initial_exploration.ipynb']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import s3\n",
    "from pprintpp import pprint as pp\n",
    "from sklearn.externals import joblib\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# Load in Bucket\n",
    "bucket = s3.Bucket('yelpchallenge1')\n",
    "# Look inside the bucket.\n",
    "bucket.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    ### ***** DO NOT RUN. ******* #### \n",
    "                  ### ***** ALREADY INSTALLED. ****** ###\n",
    "\n",
    "# Only have to run this once.\n",
    "# Installs the .csv 'Locally' on SageMaker Instance\n",
    "\n",
    "#bucket.get('datasets/df.csv', 'df.csv')\n",
    "\n",
    "# Installing user.json 'Locally'\n",
    "#bucket.get('datasets/user.json', 'user.json')\n",
    "\n",
    "\n",
    "    # Load in Bucket\n",
    "# bucket = s3.Bucket('yelpchallenge1')\n",
    "    # Look inside the bucket.\n",
    "# bucket.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Read-in df.csv\n",
    "df = pd.read_csv('df.csv')\n",
    "\n",
    "    # Read-in review_df.csv\n",
    "review_df = pd.read_csv('review.csv')\n",
    "\n",
    "    # Read-in dtm_final.csv (FINAL)\n",
    "dtm_final = pd.read_csv('dtm_final.csv')\n",
    "\n",
    "    # import Vectorizer Model\n",
    "vect2 = joblib.load('vect_2.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports: \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Training Data. \n",
    "    # X_train will include All 135,000 Rows, for 773 Vectorized Words(Columns)\n",
    "    # y_train or the Target Variable  will include all 135,000 Rows, for the stars Column.     \n",
    "X_train = dtm_final.iloc[:, 0:773]\n",
    "y_train = dtm_final.iloc[:, 773:774]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform. '  (0, 303)\t0.2928291253691394\n  (0, 680)\t0.11002773101546855\n  (0, 592)\t0.14565528128583138\n  (0, 524)\t0.2072584072781842\n  (0, 6)\t0.39740790104238377\n  (0, 676)\t0.2616019302844405\n  (0, 77)\t0.2660758124453487\n  (0, 344)\t0.18371335060069288\n  (0, 655)\t0.1444574881343549\n  (0, 693)\t0.08415814098566772\n  (0, 207)\t0.2844730508454019\n  (0, 8)\t0.0698290738683453\n  (0, 56)\t0.23871911128994652\n  (0, 375)\t0.08661973974387839\n  (0, 209)\t0.23762191417114226\n  (0, 202)\t0.16207525767487294\n  (0, 138)\t0.06902711676550477\n  (0, 258)\t0.26881395269403136\n  (0, 123)\t0.1359548153062746\n  (0, 83)\t0.15021774751951497\n  (0, 354)\t0.2145943246350761\n  (0, 126)\t0.2862839978064905\n  (1, 303)\t0.020866102788173326\n  (1, 680)\t0.04704142612912794\n  (1, 592)\t0.03113684201104495\n  :\t:\n  (134998, 448)\t0.10065064816244558\n  (134998, 523)\t0.21584690446362662\n  (134998, 649)\t0.11334342506633152\n  (134998, 5)\t0.11510670906958285\n  (134998, 269)\t0.1062707674490976\n  (134998, 111)\t0.0893846331307269\n  (134999, 303)\t0.09967010083950832\n  (134999, 655)\t0.07375338292198415\n  (134999, 8)\t0.21390917801268833\n  (134999, 375)\t0.17689630122852895\n  (134999, 495)\t0.09980741952913119\n  (134999, 94)\t0.147950351047455\n  (134999, 331)\t0.11840038503893123\n  (134999, 442)\t0.19320888301392256\n  (134999, 176)\t0.19059224279085252\n  (134999, 199)\t0.19027070634663504\n  (134999, 304)\t0.18239475942355193\n  (134999, 178)\t0.29661124954673435\n  (134999, 446)\t0.18569968885543528\n  (134999, 297)\t0.30706181950065103\n  (134999, 308)\t0.4750323640715434\n  (134999, 210)\t0.2541356267040029\n  (134999, 198)\t0.27745423758275756\n  (134999, 390)\t0.24562455613843995\n  (134999, 461)\t0.2725417742067287' (type <class 'scipy.sparse.csr.csr_matrix'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a9f15bba56cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                  \u001b[0;34m(\u001b[0m\u001b[0;34m'vect2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvect2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                  \u001b[0;31m# Classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                  \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 ])\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ydc1/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ydc1/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 raise TypeError(\"All intermediate steps should be \"\n\u001b[1;32m    166\u001b[0m                                 \u001b[0;34m\"transformers and implement fit and transform.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                                 \" '%s' (type %s) doesn't\" % (t, type(t)))\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# We allow last estimator to be None as an identity transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform. '  (0, 303)\t0.2928291253691394\n  (0, 680)\t0.11002773101546855\n  (0, 592)\t0.14565528128583138\n  (0, 524)\t0.2072584072781842\n  (0, 6)\t0.39740790104238377\n  (0, 676)\t0.2616019302844405\n  (0, 77)\t0.2660758124453487\n  (0, 344)\t0.18371335060069288\n  (0, 655)\t0.1444574881343549\n  (0, 693)\t0.08415814098566772\n  (0, 207)\t0.2844730508454019\n  (0, 8)\t0.0698290738683453\n  (0, 56)\t0.23871911128994652\n  (0, 375)\t0.08661973974387839\n  (0, 209)\t0.23762191417114226\n  (0, 202)\t0.16207525767487294\n  (0, 138)\t0.06902711676550477\n  (0, 258)\t0.26881395269403136\n  (0, 123)\t0.1359548153062746\n  (0, 83)\t0.15021774751951497\n  (0, 354)\t0.2145943246350761\n  (0, 126)\t0.2862839978064905\n  (1, 303)\t0.020866102788173326\n  (1, 680)\t0.04704142612912794\n  (1, 592)\t0.03113684201104495\n  :\t:\n  (134998, 448)\t0.10065064816244558\n  (134998, 523)\t0.21584690446362662\n  (134998, 649)\t0.11334342506633152\n  (134998, 5)\t0.11510670906958285\n  (134998, 269)\t0.1062707674490976\n  (134998, 111)\t0.0893846331307269\n  (134999, 303)\t0.09967010083950832\n  (134999, 655)\t0.07375338292198415\n  (134999, 8)\t0.21390917801268833\n  (134999, 375)\t0.17689630122852895\n  (134999, 495)\t0.09980741952913119\n  (134999, 94)\t0.147950351047455\n  (134999, 331)\t0.11840038503893123\n  (134999, 442)\t0.19320888301392256\n  (134999, 176)\t0.19059224279085252\n  (134999, 199)\t0.19027070634663504\n  (134999, 304)\t0.18239475942355193\n  (134999, 178)\t0.29661124954673435\n  (134999, 446)\t0.18569968885543528\n  (134999, 297)\t0.30706181950065103\n  (134999, 308)\t0.4750323640715434\n  (134999, 210)\t0.2541356267040029\n  (134999, 198)\t0.27745423758275756\n  (134999, 390)\t0.24562455613843995\n  (134999, 461)\t0.2725417742067287' (type <class 'scipy.sparse.csr.csr_matrix'>) doesn't"
     ]
    }
   ],
   "source": [
    "# Create Pipeline Components\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect2', vect2), \n",
    "                 # Classifier\n",
    "                 ('clf', clf)\n",
    "                ])\n",
    "\n",
    "#Tuning\n",
    "parameters = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'vect__max_features': (500,10000),\n",
    "    'clf__n_estimators':(5, 10,),\n",
    "    'clf__max_depth':(15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=5, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_ydc1",
   "language": "python",
   "name": "conda_ydc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
