{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Up: \n",
    "Before Running the cell below, you must ensure that these have been run in Terminal **IN ORDER** : \n",
    "- conda update -n base -c defaults conda \n",
    "\n",
    "    - cd SageMaker\n",
    "    \n",
    "      - cd yelp-dataset-challenge-1-ds\n",
    "      \n",
    "         - conda env create -f environment.yml\n",
    "          \n",
    "            - source activate ydc1 \n",
    "                \n",
    "                - pip install python-decouple\n",
    "                  \n",
    "                  - pip install pprintpp\n",
    "                  \n",
    "# Spacy Installs: \n",
    "\n",
    "   - python -m spacy download en_core_web_lg\n",
    "\n",
    "        - python -m spacy link en_core_web_lg en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "#import s3\n",
    "#from pprintpp import pprint as pp\n",
    "from sklearn.externals import joblib\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# Load in Bucket\n",
    "#bucket = s3.Bucket('yelpchallenge1')\n",
    "# Look inside the bucket.\n",
    "#bucket.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    ### ***** DO NOT RUN. ******* #### \n",
    "                  ### ***** ALREADY INSTALLED. ****** ###\n",
    "\n",
    "# Only have to run this once.\n",
    "# Installs the .csv 'Locally' on SageMaker Instance\n",
    "\n",
    "#bucket.get('datasets/df.csv', 'df.csv')\n",
    "\n",
    "# Installing user.json 'Locally'\n",
    "#bucket.get('datasets/user.json', 'user.json')\n",
    "\n",
    "\n",
    "    # Load in Bucket\n",
    "# bucket = s3.Bucket('yelpchallenge1')\n",
    "    # Look inside the bucket.\n",
    "# bucket.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Read-in final.csv\n",
    "final_df = pd.read_csv('final_df.csv')\n",
    "\n",
    "    # Read-in df.csv\n",
    "#df = pd.read_csv('df.csv', nrows=250000)\n",
    "\n",
    "\n",
    "    # Read-in review_df.csv\n",
    "#review_df = pd.read_csv('review.csv')\n",
    "\n",
    "    # Read-in dtm_final.csv (FINAL)\n",
    "dtm_final = pd.read_csv('dtm_final.csv')\n",
    "\n",
    "    # import Vectorizer Model\n",
    "#vect2 = joblib.load('vect_2.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON- -PRON-</th>\n",
       "      <th>-PRON- a</th>\n",
       "      <th>-PRON- all</th>\n",
       "      <th>-PRON- also</th>\n",
       "      <th>-PRON- and</th>\n",
       "      <th>...</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>would be</th>\n",
       "      <th>would have</th>\n",
       "      <th>would not</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yet</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.343331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.314034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.080641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.515313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02601</td>\n",
       "      <td>0.027762</td>\n",
       "      <td>0.021839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028812</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1    -PRON-  -PRON-    \\\n",
       "0           0             0               0  0.069829       0.0   \n",
       "1           1             1               1  0.343331       0.0   \n",
       "2           2             2               2  0.314034       0.0   \n",
       "3           3             3               3  0.080641       0.0   \n",
       "4           4             4               4  0.515313       0.0   \n",
       "\n",
       "   -PRON- -PRON-  -PRON- a  -PRON- all  -PRON- also  -PRON- and  ...  \\\n",
       "0       0.000000       0.0         0.0          0.0    0.000000  ...   \n",
       "1       0.000000       0.0         0.0          0.0    0.047998  ...   \n",
       "2       0.000000       0.0         0.0          0.0    0.000000  ...   \n",
       "3       0.000000       0.0         0.0          0.0    0.000000  ...   \n",
       "4       0.020392       0.0         0.0          0.0    0.043038  ...   \n",
       "\n",
       "      worth     would  would be  would have  would not     wrong      year  \\\n",
       "0  0.000000  0.000000       0.0         0.0    0.00000  0.000000  0.000000   \n",
       "1  0.052035  0.000000       0.0         0.0    0.00000  0.000000  0.000000   \n",
       "2  0.000000  0.000000       0.0         0.0    0.00000  0.000000  0.093163   \n",
       "3  0.000000  0.087372       0.0         0.0    0.00000  0.000000  0.000000   \n",
       "4  0.000000  0.029004       0.0         0.0    0.02601  0.027762  0.021839   \n",
       "\n",
       "   yelp       yet  stars  \n",
       "0   0.0  0.000000    1.0  \n",
       "1   0.0  0.000000    5.0  \n",
       "2   0.0  0.000000    5.0  \n",
       "3   0.0  0.000000    5.0  \n",
       "4   0.0  0.028812    1.0  \n",
       "\n",
       "[5 rows x 777 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_final = dtm_final.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_final = dtm_final.drop(columns = ['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON- -PRON-</th>\n",
       "      <th>-PRON- a</th>\n",
       "      <th>-PRON- all</th>\n",
       "      <th>-PRON- also</th>\n",
       "      <th>-PRON- and</th>\n",
       "      <th>-PRON- be</th>\n",
       "      <th>-PRON- but</th>\n",
       "      <th>-PRON- can</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>would be</th>\n",
       "      <th>would have</th>\n",
       "      <th>would not</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.343331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047998</td>\n",
       "      <td>0.122973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.314034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.080641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.515313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.027566</td>\n",
       "      <td>0.028836</td>\n",
       "      <td>0.020320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02601</td>\n",
       "      <td>0.027762</td>\n",
       "      <td>0.021839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     -PRON-  -PRON-    -PRON- -PRON-  -PRON- a  -PRON- all  -PRON- also  \\\n",
       "0  0.069829       0.0       0.000000       0.0         0.0          0.0   \n",
       "1  0.343331       0.0       0.000000       0.0         0.0          0.0   \n",
       "2  0.314034       0.0       0.000000       0.0         0.0          0.0   \n",
       "3  0.080641       0.0       0.000000       0.0         0.0          0.0   \n",
       "4  0.515313       0.0       0.020392       0.0         0.0          0.0   \n",
       "\n",
       "   -PRON- and  -PRON- be  -PRON- but  -PRON- can  ...      work     worth  \\\n",
       "0    0.000000   0.000000    0.000000    0.000000  ...  0.000000  0.000000   \n",
       "1    0.047998   0.122973    0.000000    0.000000  ...  0.000000  0.052035   \n",
       "2    0.000000   0.039198    0.000000    0.086683  ...  0.084567  0.000000   \n",
       "3    0.000000   0.110721    0.000000    0.000000  ...  0.000000  0.000000   \n",
       "4    0.043038   0.027566    0.028836    0.020320  ...  0.000000  0.000000   \n",
       "\n",
       "      would  would be  would have  would not     wrong      year  yelp  \\\n",
       "0  0.000000       0.0         0.0    0.00000  0.000000  0.000000   0.0   \n",
       "1  0.000000       0.0         0.0    0.00000  0.000000  0.000000   0.0   \n",
       "2  0.000000       0.0         0.0    0.00000  0.000000  0.093163   0.0   \n",
       "3  0.087372       0.0         0.0    0.00000  0.000000  0.000000   0.0   \n",
       "4  0.029004       0.0         0.0    0.02601  0.027762  0.021839   0.0   \n",
       "\n",
       "        yet  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.028812  \n",
       "\n",
       "[5 rows x 773 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95000, 773)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'useful', 'funny', 'cool', 'text', 'tokens'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping All Rows with 0 in Interactions Column \n",
    "final_df = final_df[final_df.useful !=0]\n",
    "final_df = final_df[final_df.funny !=0]\n",
    "final_df = final_df[final_df.cool !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Tracy dessert had a big name in Hong Kong and ...</td>\n",
       "      <td>['tracy', 'dessert', 'hong', 'kong', 'markham'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This place has gone down hill.  Clearly they h...</td>\n",
       "      <td>['place', 'gone', 'hill', 'clearly', 'staff', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>I love chinese food and I love mexican food. W...</td>\n",
       "      <td>['love', 'chinese', 'food', 'love', 'mexican',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9</td>\n",
       "      <td>If you are looking for the best pierogies in P...</td>\n",
       "      <td>['looking', 'best', 'pierogies', 'pittsburgh',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, I must recommend not to conduct...</td>\n",
       "      <td>['unfortunately', 'recommend', 'conduct', 'bus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  useful  funny  cool  \\\n",
       "0           0     5.0    4.0     5   \n",
       "1           1     3.0    1.0     1   \n",
       "2           2     1.0    7.0     1   \n",
       "3           3     9.0    6.0     9   \n",
       "4           4     7.0    1.0     1   \n",
       "\n",
       "                                                text  \\\n",
       "0  Tracy dessert had a big name in Hong Kong and ...   \n",
       "1  This place has gone down hill.  Clearly they h...   \n",
       "2  I love chinese food and I love mexican food. W...   \n",
       "3  If you are looking for the best pierogies in P...   \n",
       "4  Unfortunately, I must recommend not to conduct...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['tracy', 'dessert', 'hong', 'kong', 'markham'...  \n",
       "1  ['place', 'gone', 'hill', 'clearly', 'staff', ...  \n",
       "2  ['love', 'chinese', 'food', 'love', 'mexican',...  \n",
       "3  ['looking', 'best', 'pierogies', 'pittsburgh',...  \n",
       "4  ['unfortunately', 'recommend', 'conduct', 'bus...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df['useful'].dtype)\n",
    "print(final_df['funny'].dtype)\n",
    "print(final_df['cool'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting columns with Dtypes Float64 to Int64 \n",
    "final_df['useful'] = final_df['useful'].astype('Float64')\n",
    "final_df['funny'] = final_df['funny'].astype('Float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df['useful'].dtype)\n",
    "print(final_df['funny'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Tracy dessert had a big name in Hong Kong and ...</td>\n",
       "      <td>['tracy', 'dessert', 'hong', 'kong', 'markham'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   useful  funny  cool                                               text  \\\n",
       "0     5.0    4.0     5  Tracy dessert had a big name in Hong Kong and ...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['tracy', 'dessert', 'hong', 'kong', 'markham'...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(index=True)\n",
    "final_df.to_csv(r'final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = dtm_final.iloc[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON- -PRON-</th>\n",
       "      <th>-PRON- a</th>\n",
       "      <th>-PRON- all</th>\n",
       "      <th>-PRON- also</th>\n",
       "      <th>-PRON- and</th>\n",
       "      <th>-PRON- be</th>\n",
       "      <th>-PRON- but</th>\n",
       "      <th>-PRON- can</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>would be</th>\n",
       "      <th>would have</th>\n",
       "      <th>would not</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.343331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047998</td>\n",
       "      <td>0.122973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.314034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.080641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.515313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.027566</td>\n",
       "      <td>0.028836</td>\n",
       "      <td>0.020320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02601</td>\n",
       "      <td>0.027762</td>\n",
       "      <td>0.021839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     -PRON-  -PRON-    -PRON- -PRON-  -PRON- a  -PRON- all  -PRON- also  \\\n",
       "0  0.069829       0.0       0.000000       0.0         0.0          0.0   \n",
       "1  0.343331       0.0       0.000000       0.0         0.0          0.0   \n",
       "2  0.314034       0.0       0.000000       0.0         0.0          0.0   \n",
       "3  0.080641       0.0       0.000000       0.0         0.0          0.0   \n",
       "4  0.515313       0.0       0.020392       0.0         0.0          0.0   \n",
       "\n",
       "   -PRON- and  -PRON- be  -PRON- but  -PRON- can  ...      work     worth  \\\n",
       "0    0.000000   0.000000    0.000000    0.000000  ...  0.000000  0.000000   \n",
       "1    0.047998   0.122973    0.000000    0.000000  ...  0.000000  0.052035   \n",
       "2    0.000000   0.039198    0.000000    0.086683  ...  0.084567  0.000000   \n",
       "3    0.000000   0.110721    0.000000    0.000000  ...  0.000000  0.000000   \n",
       "4    0.043038   0.027566    0.028836    0.020320  ...  0.000000  0.000000   \n",
       "\n",
       "      would  would be  would have  would not     wrong      year  yelp  \\\n",
       "0  0.000000       0.0         0.0    0.00000  0.000000  0.000000   0.0   \n",
       "1  0.000000       0.0         0.0    0.00000  0.000000  0.000000   0.0   \n",
       "2  0.000000       0.0         0.0    0.00000  0.000000  0.093163   0.0   \n",
       "3  0.087372       0.0         0.0    0.00000  0.000000  0.000000   0.0   \n",
       "4  0.029004       0.0         0.0    0.02601  0.027762  0.021839   0.0   \n",
       "\n",
       "        yet  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.028812  \n",
       "\n",
       "[5 rows x 773 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep: \n",
    "\n",
    "**Description**: \n",
    "\n",
    "Combining based on their *Unique Account ID's.*\n",
    "The end Product will be One DataFrame Consisting of Each Account:\n",
    "- **Name**, \n",
    "- **User_ID**,\n",
    "- **Review_ID**,\n",
    "- **Text**,\n",
    "- **That Users respective review(s)**,\n",
    "- **Interactions that Review (i.e: Cool, Funny, Useful)**  \n",
    "\n",
    "The goal of the model is to have the ability to type in the Review you are wanting to post on Yelp, and give the User the ability to Predict What type of Interaction they would potentially receive and Total Number of each interaction. The model Accuracy will be Displayed beside the Prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier: Useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports: \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining\n",
    "# tokenizer\n",
    "def tokenize(document):\n",
    "    doc = nlp(document)\n",
    "    return [token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True)]\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=0.025, max_df=.95, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=15, p=2, radius=1.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on TF-IDF Vectors\n",
    "nn  = NearestNeighbors(n_neighbors=15, algorithm='ball_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Fake Review for Testing: \n",
    "fake_review = \"\"\"\n",
    "After finshing our dinner we heard a loud crash come from the back of the place The next thing we saw was a cook running out of the kitchen chasing a cat with a cleaver covered in blood and animal hair... My children were traumatized.. Given that the cat looked exactly like Whiskers, who ran away last week. \n",
    "I had no idea how I was going to parent that situation given that I was completley drunk and could not stop laughing. The beer was a little flat, the 'chicken' was a little gamey. \n",
    "Service was great 4 Stars.\n",
    "\"\"\"\n",
    "\n",
    "# tokenizer\n",
    "vect_review = tfidf.fit_transform(tokenize(fake_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Dataset into training sets\n",
    "\n",
    "    # Using 10,000 Rows. \n",
    "\n",
    "reviews = final_df['tokens'].iloc[0:25000]\n",
    "interactions = final_df['useful'].iloc[0:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haden/anaconda3/envs/ydc1/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.75, 1.0), 'vect__min_df': (0.02, 0.05), 'vect__max_features': (500, 1000), 'clf__n_estimators': (5, 10), 'clf__max_depth': (15, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Pipeline Components\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect', vect), \n",
    "                 # Classifier\n",
    "                 ('clf', rfc)\n",
    "                ])\n",
    "\n",
    "\n",
    "#Tuning\n",
    "parameters = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'vect__min_df': (.02, 0.05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators':(5, 10,),\n",
    "    'clf__max_depth':(15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs= -1, verbose=1)\n",
    "grid_search.fit(reviews, interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24655577956989247"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 15,\n",
       " 'clf__n_estimators': 10,\n",
       " 'vect__max_df': 0.75,\n",
       " 'vect__max_features': 500,\n",
       " 'vect__min_df': 0.02}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "# Fake Review Interaction 'Useful' Prediction: \n",
    "\n",
    "useful_pred = grid_search.predict([r'vect_review'])\n",
    "print(useful_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickling Model with JobLib\n",
    "joblib.dump(useful_pred, 'useful_clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Fake Review for Testing: \n",
    "fake_review4 = \"\"\"\n",
    "After finshing our dinner we heard a loud crash come from the back of the place The next thing we saw was a cook running out of the kitchen chasing a cat with a cleaver covered in blood and animal hair... My children were traumatized.. Given that the cat looked exactly like Whiskers, who ran away last week. \n",
    "I had no idea how I was going to parent that situation given that I was completley drunk and could not stop laughing. The beer was a little flat, the 'chicken' was a little gamey. \n",
    "Service was great 4 Stars.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing Fake_Review4\n",
    "vect_review4 = tfidf.fit_transform(tokenize(fake_review4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_pred4 = grid_search.predict([r'vect_review4'])\n",
    "print(useful_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "vect_review2 = tfidf.fit_transform(tokenize(fake_review2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_pred2 = grid_search.predict([r'vect_review2'])\n",
    "print(useful_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['text'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropped all 0's from Rows \n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Fake Review5 for Testing: \n",
    "fake_review5 = \"\"\"\n",
    "After finshing our dinner we heard a loud crash come from the back of the place The next thing we saw was a cook running out of the kitchen chasing a cat with a cleaver covered in blood and animal hair... My children were traumatized.. Given that the cat looked exactly like Whiskers, who ran away last week. \n",
    "I had no idea how I was going to parent that situation given that I was completley drunk and could not stop laughing. The beer was a little flat, the 'chicken' was a little gamey. \n",
    "Service was great 4 Stars.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing Fake_Review5\n",
    "vect_review5 = tfidf.fit_transform(tokenize(fake_review5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake Review Interaction 'Useful' Prediction: \n",
    "\n",
    "useful_pred5 = grid_search.predict([r'vect_review5'])\n",
    "print(useful_pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still getting 0...... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "# Testing with a Randomly pulled Review from Final_df for tokenization and prediction. \n",
    "review_888 = final_df['text'].iloc[888]\n",
    "# Interaction 'Useful' Prediction: \n",
    "vect_review6 = tfidf.fit_transform(tokenize(review_888))\n",
    "useful_pred6 = grid_search.predict([r'vect_review6'])\n",
    "print(useful_pred6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier for 'Funny' after Changes: as of 1/09/2020 at 7:00PM EST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports: \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Variables for Training \n",
    "interactions = final_df['funny']\n",
    "\n",
    "# Splitting Dataset into training sets\n",
    "\n",
    "    # Using 10,000 Rows. \n",
    "\n",
    "reviews = final_df['tokens'].iloc[0:10000]\n",
    "interactions = interactions.iloc[0:10000]\n",
    "\n",
    "# Fit on TF-IDF Vectors\n",
    "nn  = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "nn.fit(dtm)\n",
    "\n",
    "# Defining\n",
    "# tokenizer\n",
    "def tokenize(document):\n",
    "    doc = nlp(document)\n",
    "    return [token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True)]\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=0.025, max_df=.95, ngram_range=(1,2))\n",
    "\n",
    "\n",
    "# Creating Fake Review for Testing: \n",
    "fake_review = \"\"\"\n",
    "After finshing our dinner we heard a loud crash come from the back of the place The next thing we saw was a cook running out of the kitchen chasing a cat with a cleaver covered in blood and animal hair... My children were traumatized.. Given that the cat looked exactly like Whiskers, who ran away last week. \n",
    "I had no idea how I was going to parent that situation given that I was completley drunk and could not stop laughing. The beer was a little flat, the 'chicken' was a little gamey. \n",
    "Service was great 4 Stars.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "vect_review1 = tfidf.fit_transform(tokenize(fake_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline Components\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect', vect), \n",
    "                 # Classifier\n",
    "                 ('clf', rfc)\n",
    "                ])\n",
    "\n",
    "\n",
    "#Tuning\n",
    "parameters = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'vect__min_df': (.02, 0.05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators':(5, 10,),\n",
    "    'clf__max_depth':(15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs= -1, verbose=1)\n",
    "grid_search.fit(reviews, interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score\n",
    "print(grid_search.best_score_) \n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake Review Interaction 'Cool' Prediction: \n",
    "\n",
    "cool_pred = grid_search.predict([r'vect_review1'])\n",
    "print(cool_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickling Model with JobLib\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(regressor, 'regressor.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDRegressor Model: 'Useful' Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   33.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__n_iter_no_change': 45} 0.01220866577361746\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "scaler = StandardScaler(with_mean=False, with_std=False)\n",
    "sgdc = SGDRegressor(alpha=0.0001, \n",
    "                    average=False, \n",
    "                    early_stopping=False,\n",
    "                    epsilon=0.1,\n",
    "                    eta0=0.01, \n",
    "                    fit_intercept=True, \n",
    "                    l1_ratio=0.15,\n",
    "                    learning_rate='adaptive', \n",
    "                    loss='squared_loss', \n",
    "                    max_iter=1000,\n",
    "                    n_iter_no_change=42, \n",
    "                    penalty='l2', \n",
    "                    power_t=0.25, \n",
    "                    random_state=69,\n",
    "                    shuffle=True, \n",
    "                    tol=0.001, \n",
    "                    validation_fraction=0.1, \n",
    "                    verbose=0,\n",
    "                    warm_start=False)\n",
    "\n",
    "pipe = Pipeline([('vect', tfidf), \n",
    "                 ('scaler', scaler),\n",
    "                 ('clf', sgdc)])\n",
    "# Fit Pipeline\n",
    "pipe.fit(final_df['tokens'].astype(str), final_df['useful'])\n",
    "\n",
    "# Declaring some parameters\n",
    "parameters = {\n",
    "    'clf__n_iter_no_change' : (45, 50),\n",
    "\n",
    "}\n",
    "\n",
    "# grid Search\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Find the best fits\n",
    "grid_search.fit(final_df['tokens'].astype(str), final_df['useful'])\n",
    "\n",
    "# Best accuracy score via grid search\n",
    "print(grid_search.best_params_, grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_pred = grid_search.predict(final_df['tokens'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.377634139321624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "useful                                                    5\n",
       "funny                                                     5\n",
       "cool                                                      5\n",
       "text      This place is very unimpressive I've had bette...\n",
       "tokens    ['place', 'unimpressive', 'better', 'tasting',...\n",
       "Name: 420, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(useful_pred[420])\n",
    "final_df.iloc[420]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDRegressor Model: 'Funny' Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 2 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__n_iter_no_change': 50} -0.0033569464219035746\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "scaler = StandardScaler(with_mean=False, with_std=False)\n",
    "sgdc = SGDRegressor(alpha=0.0001, \n",
    "                    average=False, \n",
    "                    early_stopping=False,\n",
    "                    epsilon=0.1,\n",
    "                    eta0=0.01, \n",
    "                    fit_intercept=True, \n",
    "                    l1_ratio=0.15,\n",
    "                    learning_rate='adaptive', \n",
    "                    loss='squared_loss', \n",
    "                    max_iter=1000,\n",
    "                    n_iter_no_change=42, \n",
    "                    penalty='l2', \n",
    "                    power_t=0.25, \n",
    "                    random_state=69,\n",
    "                    shuffle=True, \n",
    "                    tol=0.001, \n",
    "                    validation_fraction=0.1, \n",
    "                    verbose=0,\n",
    "                    warm_start=False)\n",
    "\n",
    "pipe = Pipeline([('vect', tfidf), \n",
    "                 ('scaler', scaler),\n",
    "                 ('clf', sgdc)])\n",
    "# Fit Pipeline\n",
    "pipe.fit(final_df['tokens'].astype(str), final_df['cool'])\n",
    "\n",
    "# Declaring some parameters\n",
    "parameters = {\n",
    "    'clf__n_iter_no_change' : (45, 50),\n",
    "\n",
    "}\n",
    "\n",
    "# grid Search\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=15, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Find the best fits\n",
    "grid_search.fit(final_df['tokens'].astype(str), final_df['cool'])\n",
    "\n",
    "# Best accuracy score via grid search\n",
    "print(grid_search.best_params_, grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cool_pred = grid_search.predict(final_df['tokens'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4867875128636214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "useful                                                    9\n",
       "funny                                                     5\n",
       "cool                                                      5\n",
       "text      Over the weekend my friend and I had intense c...\n",
       "tokens    ['weekend', 'friend', 'intense', 'cravings', '...\n",
       "Name: 400, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted Cool Votes: \n",
    "print(cool_pred[400])\n",
    "\n",
    "# Actual Votes: \n",
    "final_df.iloc[400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Regressor: 'Cool' Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 2 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__n_iter_no_change': 45} -0.007132759014738393\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "scaler = StandardScaler(with_mean=False, with_std=False)\n",
    "sgdc = SGDRegressor(alpha=0.0001, \n",
    "                    average=False, \n",
    "                    early_stopping=False,\n",
    "                    epsilon=0.1,\n",
    "                    eta0=0.01, \n",
    "                    fit_intercept=True, \n",
    "                    l1_ratio=0.15,\n",
    "                    learning_rate='adaptive', \n",
    "                    loss='squared_loss', \n",
    "                    max_iter=1000,\n",
    "                    n_iter_no_change=42, \n",
    "                    penalty='l2', \n",
    "                    power_t=0.25, \n",
    "                    random_state=69,\n",
    "                    shuffle=True, \n",
    "                    tol=0.001, \n",
    "                    validation_fraction=0.1, \n",
    "                    verbose=0,\n",
    "                    warm_start=False)\n",
    "\n",
    "pipe = Pipeline([('vect', tfidf), \n",
    "                 ('scaler', scaler),\n",
    "                 ('clf', sgdc)])\n",
    "# Fit Pipeline\n",
    "pipe.fit(final_df['tokens'].astype(str), final_df['funny'])\n",
    "\n",
    "# Declaring some parameters\n",
    "parameters = {\n",
    "    'clf__n_iter_no_change' : (45, 50),\n",
    "\n",
    "}\n",
    "\n",
    "# grid Search\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=15, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Find the best fits\n",
    "grid_search.fit(final_df['tokens'].astype(str), final_df['funny'])\n",
    "\n",
    "# Best accuracy score via grid search\n",
    "print(grid_search.best_params_, grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "funny_pred = grid_search.predict(final_df['tokens'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.414489005549756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "useful                                                    6\n",
       "funny                                                     3\n",
       "cool                                                      3\n",
       "text      What happened to Roy's?? Their butterfish used...\n",
       "tokens    ['happened', 'butterfish', 'defrosted', 'slice...\n",
       "Name: 3000, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted Funny Votes: \n",
    "print(funny_pred[3000])\n",
    "\n",
    "# Actual Votes:\n",
    "final_df.iloc[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another Test: \n",
    "# Predicted Funny Votes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing: FINAL as of 1/10/2020 at 4:49 AM (EST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling Useful_Pred with JobLib\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(useful_pred, 'useful.joblib')\n",
    "\n",
    "# Pickling Cool_Pred with JobLib\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(cool_pred, 'cool.joblib')\n",
    "\n",
    "# Pickling Funny_Pred with JobLib\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(funny_pred, 'funny.joblib');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in Pickled Models\n",
    "\n",
    "# Useful\n",
    "useful_model = joblib.load('useful.joblib')\n",
    "\n",
    "# Cool \n",
    "cool_model = joblib.load('cool.joblib')\n",
    "\n",
    "# Funny \n",
    "funny_model = joblib.load('funny.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful 3.0\n",
      "Funny 2.0\n",
      "Cool 2.0\n"
     ]
    }
   ],
   "source": [
    "# Prediction Time: \n",
    "# Predicted Votes: \n",
    "print('Useful', round(useful_model[1086]))\n",
    "print('Funny', round(funny_model[1086]))\n",
    "print('Cool', round(cool_model[1086]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "useful                                                    4\n",
      "funny                                                     4\n",
      "cool                                                      4\n",
      "text      Forgot to take picture my bad lol.But this pla...\n",
      "tokens    ['forgot', 'picture', 'place', 'awesome', 'sta...\n",
      "Name: 1086, dtype: object\n"
     ]
    }
   ],
   "source": [
    "                                    ##### Actual Votes: ##########\n",
    "print(final_df.iloc[1086])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful 7.0\n",
      "Funny 3.0\n",
      "Cool 4.0\n"
     ]
    }
   ],
   "source": [
    " # Predicted Votes: \n",
    "print('Useful', round(useful_model[4086]))\n",
    "print('Funny', round(funny_model[4086]))\n",
    "print('Cool', round(cool_model[4086]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "useful                                                    6\n",
      "funny                                                     3\n",
      "cool                                                      2\n",
      "text      One of my favourite noodle soup restaurants in...\n",
      "tokens    ['favourite', 'noodle', 'soup', 'restaurants',...\n",
      "Name: 4086, dtype: object\n"
     ]
    }
   ],
   "source": [
    "                                    ##### Actual Votes: ##########\n",
    "print(final_df.iloc[4086])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful 5.0\n",
      "Funny 2.0\n",
      "Cool 3.0\n"
     ]
    }
   ],
   "source": [
    " # Predicted Votes: \n",
    "print('Useful', round(useful_model[2000]))\n",
    "print('Funny', round(funny_model[2000]))\n",
    "print('Cool', round(cool_model[2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "useful                                                    2\n",
      "funny                                                     2\n",
      "cool                                                      1\n",
      "text      About four years ago, I had the best meal of m...\n",
      "tokens    ['years', 'best', 'meal', 'life', 'border', 'g...\n",
      "Name: 2000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "                                    ##### Actual Votes: ##########\n",
    "print(final_df.iloc[2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPLETE: As of 1/10/2020 at 10:04 AM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    " # I am Done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ydc1] *",
   "language": "python",
   "name": "conda-env-ydc1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
