{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Up: \n",
    "Before Running the cell below, you must ensure that these have been run in Terminal **IN ORDER** : \n",
    "- conda update -n base -c defaults conda \n",
    "\n",
    "    - cd SageMaker\n",
    "    \n",
    "      - cd yelp-dataset-challenge-1-ds\n",
    "      \n",
    "         - conda env create -f environment.yml\n",
    "          \n",
    "            - source activate ydc1 \n",
    "                \n",
    "                - pip install python-decouple\n",
    "                  \n",
    "                  - pip install pprintpp\n",
    "                  \n",
    "# Spacy Installs: \n",
    "\n",
    "   - python -m spacy download en_core_web_lg\n",
    "\n",
    "        - python -m spacy link en_core_web_lg en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['API/',\n",
       " 'API/api.py',\n",
       " 'API/api_exploration.ipynb',\n",
       " 'Environments/',\n",
       " 'Environments/environment.yml',\n",
       " 'Flask_App/',\n",
       " 'Flask_App/Pipfile',\n",
       " 'Flask_App/__init__.py',\n",
       " 'Flask_App/app.py',\n",
       " 'Flask_App/models.py',\n",
       " 'Flask_App/yelp.py',\n",
       " 'Model/',\n",
       " 'Model/vect_1.sav',\n",
       " 'datasets/',\n",
       " 'datasets/df.csv',\n",
       " 'datasets/dtm.csv',\n",
       " 'notebooks/',\n",
       " 'notebooks/data_cleanup.ipynb',\n",
       " 'notebooks/official_NB.ipynb',\n",
       " 'notebooks/vectorization_exploration.ipynb',\n",
       " 'notebooks/yelp_data_initial_exploration.ipynb']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import s3\n",
    "from pprintpp import pprint as pp\n",
    "from sklearn.externals import joblib\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# Load in Bucket\n",
    "bucket = s3.Bucket('yelpchallenge1')\n",
    "# Look inside the bucket.\n",
    "bucket.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT RUN #### \n",
    "### ALREADY INSTALLED ###\n",
    "\n",
    "# Only have to run this once.\n",
    "# Installs the .csv 'Locally' on SageMaker Instance\n",
    "\n",
    "#bucket.get('datasets/df.csv', 'df.csv')\n",
    "\n",
    "    # Load in Bucket\n",
    "# bucket = s3.Bucket('yelpchallenge1')\n",
    "    # Look inside the bucket.\n",
    "# bucket.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-in df.csv\n",
    "df = pd.read_csv('df.csv')\n",
    "# Dropping Column\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "# Dropping all Missing / Na Values from Entire Dataframe\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stars          0\n",
      "text           0\n",
      "date           0\n",
      "total_votes    0\n",
      "tokens         0\n",
      "dtype: int64\n",
      "(6685874, 5)\n",
      "stars           object\n",
      "text            object\n",
      "date            object\n",
      "total_votes    float64\n",
      "tokens          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Checking Null Values and Shape\n",
    "print(df.isna().sum())\n",
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON- -PRON-</th>\n",
       "      <th>-PRON- a</th>\n",
       "      <th>-PRON- all</th>\n",
       "      <th>-PRON- also</th>\n",
       "      <th>-PRON- and</th>\n",
       "      <th>-PRON- be</th>\n",
       "      <th>-PRON- but</th>\n",
       "      <th>-PRON- can</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>would be</th>\n",
       "      <th>would have</th>\n",
       "      <th>would not</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.343331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047998</td>\n",
       "      <td>0.122973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.314034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.080641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.515313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.027566</td>\n",
       "      <td>0.028836</td>\n",
       "      <td>0.020320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02601</td>\n",
       "      <td>0.027762</td>\n",
       "      <td>0.021839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     -PRON-  -PRON-    -PRON- -PRON-  -PRON- a  -PRON- all  -PRON- also  \\\n",
       "0  0.069829       0.0       0.000000       0.0         0.0          0.0   \n",
       "1  0.343331       0.0       0.000000       0.0         0.0          0.0   \n",
       "2  0.314034       0.0       0.000000       0.0         0.0          0.0   \n",
       "3  0.080641       0.0       0.000000       0.0         0.0          0.0   \n",
       "4  0.515313       0.0       0.020392       0.0         0.0          0.0   \n",
       "\n",
       "   -PRON- and  -PRON- be  -PRON- but  -PRON- can  ...      work     worth  \\\n",
       "0    0.000000   0.000000    0.000000    0.000000  ...  0.000000  0.000000   \n",
       "1    0.047998   0.122973    0.000000    0.000000  ...  0.000000  0.052035   \n",
       "2    0.000000   0.039198    0.000000    0.086683  ...  0.084567  0.000000   \n",
       "3    0.000000   0.110721    0.000000    0.000000  ...  0.000000  0.000000   \n",
       "4    0.043038   0.027566    0.028836    0.020320  ...  0.000000  0.000000   \n",
       "\n",
       "      would  would be  would have  would not     wrong      year  yelp  \\\n",
       "0  0.000000       0.0         0.0    0.00000  0.000000  0.000000   0.0   \n",
       "1  0.000000       0.0         0.0    0.00000  0.000000  0.000000   0.0   \n",
       "2  0.000000       0.0         0.0    0.00000  0.000000  0.093163   0.0   \n",
       "3  0.087372       0.0         0.0    0.00000  0.000000  0.000000   0.0   \n",
       "4  0.029004       0.0         0.0    0.02601  0.027762  0.021839   0.0   \n",
       "\n",
       "        yet  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.028812  \n",
       "\n",
       "[5 rows x 773 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read-in dtm.csv (Original)\n",
    "#dtm = pd.read_csv('dtm.csv')\n",
    "#dtm = dtm.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Read-in dtm2.csv (Old)\n",
    "#dtm2 = pd.read_csv('dtm2.csv')\n",
    "#dtm2 = dtm2.drop(columns=['Unnamed: 0'])\n",
    "#dtm2.head()\n",
    "\n",
    "# Read-in dtm_final.csv (FINAL)\n",
    "dtm_final = pd.read_csv('dtm_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Vectorizer models\n",
    "#vect = joblib.load('vect_1.sav')\n",
    "vect2 = joblib.load('vect_2.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # ***** New DTM DF HAS BEEN CREATED. DO NOT RUN THIS CELL **** #\n",
    "\n",
    "# Taking Stars Column\n",
    "#stars = df['stars']\n",
    "\n",
    "# Adding stars column to dtm\n",
    "#dtm['stars']=df['stars']\n",
    "\n",
    "# Shifting 'Stars' Column to front of Df,\n",
    "#cols = list(dtm.columns)\n",
    "#cols = [cols[-1]] + cols[:-1]\n",
    "#dtm = dtm[cols]\n",
    "\n",
    "# Dropping \"-PRON-\", 'year -PRON-', and ' ' Columns\n",
    "#dtm = dtm.drop(columns=[' ', '  -PRON-', 'year -PRON-'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "             # ***** New DTM2 DF HAS BEEN CREATED. DO NOT RUN THIS CELL **** #\n",
    "# Taking Stars Column\n",
    "#stars = df['stars']\n",
    "\n",
    "# Adding stars column to dtm\n",
    "#dtm2['stars']=df['stars']\n",
    "\n",
    "# Shifting 'Stars' Column to front of Df,\n",
    "#cols = list(dtm2.columns)\n",
    "#cols = [cols[-1]] + cols[:-1]\n",
    "#dtm2 = dtm2[cols]\n",
    "\n",
    "#dtm2 = dtm2.drop(columns=['stars'])\n",
    "# Dropping columns: \n",
    "#dtm2 = dtm2.drop(columns=[' ' , '  '])\n",
    "#dtm2 = dtm2.drop(columns=['  -PRON-','  i',  '  the',  '  this', '$', \"'s\"])\n",
    "# Saving dtm2.csv \n",
    "#dtm2.to_csv(index=False)\n",
    "#dtm2.to_csv(r'dtm2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dtm2.csv \n",
    "#dtm2.to_csv(index=False)\n",
    "#dtm2.to_csv(r'dtm2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cut 135,000 Rows of df['stars'] Column to fix Memory Error. \n",
    "# Label as \"stars\"\n",
    "stars = df.stars[0:135000]\n",
    "stars.shape\n",
    "# Adding stars to dtm2\n",
    "dtm2['stars']=df['stars'][0:135000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm2.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_final = dtm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_final.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dtm_final.csv \n",
    "dtm_final.to_csv(index=False)\n",
    "dtm_final.to_csv(r'dtm_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports: \n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost.sklearn import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135000, 774)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Training Data. \n",
    "    # X_train will include All 135,000 Rows, for 773 Vectorized Words(Columns)\n",
    "    # y_train or the Target Variable  will include all 135,000 Rows, for the stars Column. \n",
    "    \n",
    "X_train = dtm_final.iloc[:, 0:773]\n",
    "y_train = dtm_final.iloc[:, 773:774]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_ydc1",
   "language": "python",
   "name": "conda_ydc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
