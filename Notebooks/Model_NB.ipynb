{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Up: \n",
    "Before Running the cell below, you must ensure that these have been run in Terminal **IN ORDER** : \n",
    "- conda update -n base -c defaults conda \n",
    "\n",
    "    - cd SageMaker\n",
    "    \n",
    "      - cd yelp-dataset-challenge-1-ds\n",
    "      \n",
    "         - conda env create -f environment.yml\n",
    "          \n",
    "            - source activate ydc1 \n",
    "                \n",
    "                - pip install python-decouple\n",
    "                  \n",
    "                  - pip install pprintpp\n",
    "                  \n",
    "# Spacy Installs: \n",
    "\n",
    "   - python -m spacy download en_core_web_lg\n",
    "\n",
    "        - python -m spacy link en_core_web_lg en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['API/',\n",
       " 'API/api.py',\n",
       " 'API/api_exploration.ipynb',\n",
       " 'Environments/',\n",
       " 'Environments/environment.yml',\n",
       " 'Flask_App/',\n",
       " 'Flask_App/Pipfile',\n",
       " 'Flask_App/__init__.py',\n",
       " 'Flask_App/app.py',\n",
       " 'Flask_App/models.py',\n",
       " 'Flask_App/yelp.py',\n",
       " 'Model/',\n",
       " 'Model/vect_1.sav',\n",
       " 'datasets/',\n",
       " 'datasets/df.csv',\n",
       " 'datasets/dtm.csv',\n",
       " 'datasets/dtm_final.csv',\n",
       " 'datasets/user.json',\n",
       " 'notebooks/',\n",
       " 'notebooks/data_cleanup.ipynb',\n",
       " 'notebooks/official_NB.ipynb',\n",
       " 'notebooks/vectorization_exploration.ipynb',\n",
       " 'notebooks/yelp_data_initial_exploration.ipynb']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import s3\n",
    "from pprintpp import pprint as pp\n",
    "from sklearn.externals import joblib\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# Load in Bucket\n",
    "bucket = s3.Bucket('yelpchallenge1')\n",
    "# Look inside the bucket.\n",
    "bucket.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    ### ***** DO NOT RUN. ******* #### \n",
    "                  ### ***** ALREADY INSTALLED. ****** ###\n",
    "\n",
    "# Only have to run this once.\n",
    "# Installs the .csv 'Locally' on SageMaker Instance\n",
    "\n",
    "#bucket.get('datasets/df.csv', 'df.csv')\n",
    "\n",
    "# Installing user.json 'Locally'\n",
    "#bucket.get('datasets/user.json', 'user.json')\n",
    "\n",
    "\n",
    "    # Load in Bucket\n",
    "# bucket = s3.Bucket('yelpchallenge1')\n",
    "    # Look inside the bucket.\n",
    "# bucket.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "                             ### ***** DO NOT RUN. ******* #### \n",
    "                          ### ***** ALREADY INSTALLED. ****** ###\n",
    "\n",
    "# Further Cleaning of df.csv \n",
    "\n",
    "    # Dropping Column\n",
    "# df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "    # Dropping all Missing / Na Values from Entire Dataframe\n",
    "# df = df.dropna()\n",
    "# Saving Further Cleaned df.csv \n",
    "#df.to_csv(index=False)\n",
    "#df.to_csv(r'df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'review.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6a6a3eea2d81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Import review.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'review.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     review = json.loads(\"[\" + \n\u001b[1;32m     20\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"}\\n{\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"},\\n{\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'review.json'"
     ]
    }
   ],
   "source": [
    "                              # ******* DO NOT RUN ******* # \n",
    "                            # ***** ALREADY COMPLETE. ****** # \n",
    "\n",
    "\n",
    " # import user.json\n",
    "\n",
    "#import json\n",
    "#with open('user.json') as f:\n",
    "    #user = json.loads(\"[\" + \n",
    "       # f.read().replace(\"}\\n{\", \"},\\n{\") + \n",
    "   # \"]\")\n",
    "\n",
    "# convert user.json files to pandas DataFrame 'user_df'\n",
    "#user_df = pd.DataFrame(user)\n",
    "\n",
    "\n",
    "# Import review.json \n",
    "with open('datasets/review.json') as f:\n",
    "    review = json.loads(\"[\" + \n",
    "        f.read().replace(\"}\\n{\", \"},\\n{\") + \n",
    "    \"]\")\n",
    "\n",
    "# convert review.json files to pandas DataFrame 'review_df'\n",
    "review_df = pd.DataFrame(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_stars</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_photos</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>...</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>fans</th>\n",
       "      <th>friends</th>\n",
       "      <th>funny</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>yelping_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>2015,2016,2017</td>\n",
       "      <td>5</td>\n",
       "      <td>c78V-rj8NQcQjOI8KP3UEA, alRMgPcngYSCJ5naFRBz5g...</td>\n",
       "      <td>17</td>\n",
       "      <td>Rashmi</td>\n",
       "      <td>95</td>\n",
       "      <td>84</td>\n",
       "      <td>l6BmjZMeQD3rDxWUbiAiow</td>\n",
       "      <td>2013-10-08 23:11:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>kEBTgDvFX754S68FllfCaA, aB2DynOxNOJK9st2ZeGTPg...</td>\n",
       "      <td>22</td>\n",
       "      <td>Jenna</td>\n",
       "      <td>33</td>\n",
       "      <td>48</td>\n",
       "      <td>4XChL029mKr5hydo79Ljxg</td>\n",
       "      <td>2013-02-21 22:29:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4N-HU_T32hLENLntsNKNBg, pSY2vwWLgWfGVAAiKQzMng...</td>\n",
       "      <td>8</td>\n",
       "      <td>David</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>bc8C_eETBWL0olvFSJJd0w</td>\n",
       "      <td>2013-10-04 00:16:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>RZ6wS38wnlXyj-OOdTzBxA, l5jxZh1KsgI8rMunm-GN6A...</td>\n",
       "      <td>4</td>\n",
       "      <td>Angela</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>dD0gZpBctWGdWo9WlGuhlA</td>\n",
       "      <td>2014-05-22 15:57:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.08</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>665</td>\n",
       "      <td>2015,2016,2017,2018</td>\n",
       "      <td>39</td>\n",
       "      <td>mbwrZ-RS76V1HoJ0bF_Geg, g64lOV39xSLRZO0aQQ6DeQ...</td>\n",
       "      <td>279</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>361</td>\n",
       "      <td>1114</td>\n",
       "      <td>MM4RJAeH6yuaN8oZDSt0RA</td>\n",
       "      <td>2013-10-23 07:02:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_stars  compliment_cool  compliment_cute  compliment_funny  \\\n",
       "0           4.03                1                0                 1   \n",
       "1           3.63                1                0                 1   \n",
       "2           3.71                0                0                 0   \n",
       "3           4.85                0                0                 0   \n",
       "4           4.08               80                0                80   \n",
       "\n",
       "   compliment_hot  compliment_list  compliment_more  compliment_note  \\\n",
       "0               2                0                0                1   \n",
       "1               1                0                0                0   \n",
       "2               0                0                0                1   \n",
       "3               1                0                0                0   \n",
       "4              28                1                1               16   \n",
       "\n",
       "   compliment_photos  compliment_plain  ...  cool                elite  fans  \\\n",
       "0                  0                 1  ...    25       2015,2016,2017     5   \n",
       "1                  0                 0  ...    16                          4   \n",
       "2                  0                 0  ...    10                          0   \n",
       "3                  0                 2  ...    14                          5   \n",
       "4                  5                57  ...   665  2015,2016,2017,2018    39   \n",
       "\n",
       "                                             friends  funny    name  \\\n",
       "0  c78V-rj8NQcQjOI8KP3UEA, alRMgPcngYSCJ5naFRBz5g...     17  Rashmi   \n",
       "1  kEBTgDvFX754S68FllfCaA, aB2DynOxNOJK9st2ZeGTPg...     22   Jenna   \n",
       "2  4N-HU_T32hLENLntsNKNBg, pSY2vwWLgWfGVAAiKQzMng...      8   David   \n",
       "3  RZ6wS38wnlXyj-OOdTzBxA, l5jxZh1KsgI8rMunm-GN6A...      4  Angela   \n",
       "4  mbwrZ-RS76V1HoJ0bF_Geg, g64lOV39xSLRZO0aQQ6DeQ...    279   Nancy   \n",
       "\n",
       "   review_count useful                 user_id        yelping_since  \n",
       "0            95     84  l6BmjZMeQD3rDxWUbiAiow  2013-10-08 23:11:33  \n",
       "1            33     48  4XChL029mKr5hydo79Ljxg  2013-02-21 22:29:06  \n",
       "2            16     28  bc8C_eETBWL0olvFSJJd0w  2013-10-04 00:16:10  \n",
       "3            17     30  dD0gZpBctWGdWo9WlGuhlA  2014-05-22 15:57:30  \n",
       "4           361   1114  MM4RJAeH6yuaN8oZDSt0RA  2013-10-23 07:02:50  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Df\n",
    "user_df.head()\n",
    "#review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn user_df into csv file. \n",
    "user_df.to_csv(index=False)\n",
    "user_df.to_csv(r'user.csv')\n",
    "# Turn review_df into csv file. \n",
    "#review_df.to_csv(index=False)\n",
    "#review_df.to_csv(r'review.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-in df.csv\n",
    "df = pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stars          0\n",
      "text           0\n",
      "date           0\n",
      "total_votes    0\n",
      "tokens         0\n",
      "dtype: int64\n",
      "(6685874, 5)\n",
      "stars           object\n",
      "text            object\n",
      "date            object\n",
      "total_votes    float64\n",
      "tokens          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Checking Null Values and Shape\n",
    "print(df.isna().sum())\n",
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-in dtm.csv (Original)\n",
    "#dtm = pd.read_csv('dtm.csv')\n",
    "#dtm = dtm.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Read-in dtm2.csv (Old)\n",
    "#dtm2 = pd.read_csv('dtm2.csv')\n",
    "#dtm2 = dtm2.drop(columns=['Unnamed: 0'])\n",
    "#dtm2.head()\n",
    "\n",
    "# Read-in dtm_final.csv (FINAL)\n",
    "dtm_final = pd.read_csv('dtm_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Vectorizer models\n",
    "#vect = joblib.load('vect_1.sav')\n",
    "vect2 = joblib.load('vect_2.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merging\n",
    "**Do NOT Run Any Cells in this Markdown**\n",
    "\n",
    "**COMPLETE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # ***** New DTM DF HAS BEEN CREATED. DO NOT RUN THIS CELL **** #\n",
    "\n",
    "# Taking Stars Column\n",
    "#stars = df['stars']\n",
    "\n",
    "# Adding stars column to dtm\n",
    "#dtm['stars']=df['stars']\n",
    "\n",
    "# Shifting 'Stars' Column to front of Df,\n",
    "#cols = list(dtm.columns)\n",
    "#cols = [cols[-1]] + cols[:-1]\n",
    "#dtm = dtm[cols]\n",
    "\n",
    "# Dropping \"-PRON-\", 'year -PRON-', and ' ' Columns\n",
    "#dtm = dtm.drop(columns=[' ', '  -PRON-', 'year -PRON-'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "             # ***** New DTM2 DF HAS BEEN CREATED. DO NOT RUN THIS CELL **** #\n",
    "# Taking Stars Column\n",
    "#stars = df['stars']\n",
    "\n",
    "# Adding stars column to dtm\n",
    "#dtm2['stars']=df['stars']\n",
    "\n",
    "# Shifting 'Stars' Column to front of Df,\n",
    "#cols = list(dtm2.columns)\n",
    "#cols = [cols[-1]] + cols[:-1]\n",
    "#dtm2 = dtm2[cols]\n",
    "\n",
    "#dtm2 = dtm2.drop(columns=['stars'])\n",
    "# Dropping columns: \n",
    "#dtm2 = dtm2.drop(columns=[' ' , '  '])\n",
    "#dtm2 = dtm2.drop(columns=['  -PRON-','  i',  '  the',  '  this', '$', \"'s\"])\n",
    "# Saving dtm2.csv \n",
    "#dtm2.to_csv(index=False)\n",
    "#dtm2.to_csv(r'dtm2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dtm2.csv \n",
    "#dtm2.to_csv(index=False)\n",
    "#dtm2.to_csv(r'dtm2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cut 135,000 Rows of df['stars'] Column to fix Memory Error. \n",
    "# Label as \"stars\"\n",
    "#stars = df.stars[0:135000]\n",
    "#stars.shape\n",
    "# Adding stars to dtm2\n",
    "#dtm2['stars']=df['stars'][0:135000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm2.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm_final = dtm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm_final.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dtm_final.csv \n",
    "#dtm_final.to_csv(index=False)\n",
    "#dtm_final.to_csv(r'dtm_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports: \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Training Data. \n",
    "    # X_train will include All 135,000 Rows, for 773 Vectorized Words(Columns)\n",
    "    # y_train or the Target Variable  will include all 135,000 Rows, for the stars Column.     \n",
    "X_train = dtm_final.iloc[:, 0:773]\n",
    "y_train = dtm_final.iloc[:, 773:774]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline Components\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "\n",
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect', vect), \n",
    "                 # Classifier\n",
    "                 ('clf', rfc)\n",
    "                ])\n",
    "\n",
    "#Tuning\n",
    "parameters = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'vect__max_features': (500,10000),\n",
    "    'clf__n_estimators':(5, 10,),\n",
    "    'clf__max_depth':(15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=5, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_ydc1",
   "language": "python",
   "name": "conda_ydc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
