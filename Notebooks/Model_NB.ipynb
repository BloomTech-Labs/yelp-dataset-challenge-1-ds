{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Up: \n",
    "Before Running the cell below, you must ensure that these have been run in Terminal **IN ORDER** : \n",
    "- conda update -n base -c defaults conda \n",
    "\n",
    "    - cd SageMaker\n",
    "    \n",
    "      - cd yelp-dataset-challenge-1-ds\n",
    "      \n",
    "         - conda env create -f environment.yml\n",
    "          \n",
    "            - source activate ydc1 \n",
    "                \n",
    "                - pip install python-decouple\n",
    "                  \n",
    "                  - pip install pprintpp\n",
    "                  \n",
    "# Spacy Installs: \n",
    "\n",
    "   - python -m spacy download en_core_web_lg\n",
    "\n",
    "        - python -m spacy link en_core_web_lg en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "#import s3\n",
    "#from pprintpp import pprint as pp\n",
    "from sklearn.externals import joblib\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# Load in Bucket\n",
    "#bucket = s3.Bucket('yelpchallenge1')\n",
    "# Look inside the bucket.\n",
    "#bucket.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    ### ***** DO NOT RUN. ******* #### \n",
    "                  ### ***** ALREADY INSTALLED. ****** ###\n",
    "\n",
    "# Only have to run this once.\n",
    "# Installs the .csv 'Locally' on SageMaker Instance\n",
    "\n",
    "#bucket.get('datasets/df.csv', 'df.csv')\n",
    "\n",
    "# Installing user.json 'Locally'\n",
    "#bucket.get('datasets/user.json', 'user.json')\n",
    "\n",
    "\n",
    "    # Load in Bucket\n",
    "# bucket = s3.Bucket('yelpchallenge1')\n",
    "    # Look inside the bucket.\n",
    "# bucket.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Read-in final.csv\n",
    "final_df = pd.read_csv('final_df.csv')\n",
    "\n",
    "    # Read-in df.csv\n",
    "#df = pd.read_csv('df.csv', nrows=250000)\n",
    "\n",
    "\n",
    "    # Read-in review_df.csv\n",
    "#review_df = pd.read_csv('review.csv')\n",
    "\n",
    "    # Read-in dtm_final.csv (FINAL)\n",
    "dtm_final = pd.read_csv('dtm_final.csv')\n",
    "\n",
    "    # import Vectorizer Model\n",
    "#vect2 = joblib.load('vect_2.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON- -PRON-</th>\n",
       "      <th>-PRON- a</th>\n",
       "      <th>-PRON- all</th>\n",
       "      <th>-PRON- also</th>\n",
       "      <th>-PRON- and</th>\n",
       "      <th>...</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>would be</th>\n",
       "      <th>would have</th>\n",
       "      <th>would not</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yet</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.343331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.314034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.080641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.515313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02601</td>\n",
       "      <td>0.027762</td>\n",
       "      <td>0.021839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028812</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1    -PRON-  -PRON-    \\\n",
       "0           0             0               0  0.069829       0.0   \n",
       "1           1             1               1  0.343331       0.0   \n",
       "2           2             2               2  0.314034       0.0   \n",
       "3           3             3               3  0.080641       0.0   \n",
       "4           4             4               4  0.515313       0.0   \n",
       "\n",
       "   -PRON- -PRON-  -PRON- a  -PRON- all  -PRON- also  -PRON- and  ...  \\\n",
       "0       0.000000       0.0         0.0          0.0    0.000000  ...   \n",
       "1       0.000000       0.0         0.0          0.0    0.047998  ...   \n",
       "2       0.000000       0.0         0.0          0.0    0.000000  ...   \n",
       "3       0.000000       0.0         0.0          0.0    0.000000  ...   \n",
       "4       0.020392       0.0         0.0          0.0    0.043038  ...   \n",
       "\n",
       "      worth     would  would be  would have  would not     wrong      year  \\\n",
       "0  0.000000  0.000000       0.0         0.0    0.00000  0.000000  0.000000   \n",
       "1  0.052035  0.000000       0.0         0.0    0.00000  0.000000  0.000000   \n",
       "2  0.000000  0.000000       0.0         0.0    0.00000  0.000000  0.093163   \n",
       "3  0.000000  0.087372       0.0         0.0    0.00000  0.000000  0.000000   \n",
       "4  0.000000  0.029004       0.0         0.0    0.02601  0.027762  0.021839   \n",
       "\n",
       "   yelp       yet  stars  \n",
       "0   0.0  0.000000    1.0  \n",
       "1   0.0  0.000000    5.0  \n",
       "2   0.0  0.000000    5.0  \n",
       "3   0.0  0.000000    5.0  \n",
       "4   0.0  0.028812    1.0  \n",
       "\n",
       "[5 rows x 777 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_final = dtm_final.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_final = dtm_final.drop(columns = ['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON- -PRON-</th>\n",
       "      <th>-PRON- a</th>\n",
       "      <th>-PRON- all</th>\n",
       "      <th>-PRON- also</th>\n",
       "      <th>-PRON- and</th>\n",
       "      <th>-PRON- be</th>\n",
       "      <th>-PRON- but</th>\n",
       "      <th>-PRON- can</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>would be</th>\n",
       "      <th>would have</th>\n",
       "      <th>would not</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     -PRON-  -PRON-    -PRON- -PRON-  -PRON- a  -PRON- all  -PRON- also  \\\n",
       "0  0.069829       0.0            0.0       0.0         0.0          0.0   \n",
       "\n",
       "   -PRON- and  -PRON- be  -PRON- but  -PRON- can  ...  work  worth  would  \\\n",
       "0         0.0        0.0         0.0         0.0  ...   0.0    0.0    0.0   \n",
       "\n",
       "   would be  would have  would not  wrong  year  yelp  yet  \n",
       "0       0.0         0.0        0.0    0.0   0.0   0.0  0.0  \n",
       "\n",
       "[1 rows x 773 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_final.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95000, 773)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['useful', 'funny', 'cool', 'text', 'tokens'], dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping All Rows with 0 in Interactions Column \n",
    "final_df = final_df[final_df.useful !=0]\n",
    "final_df = final_df[final_df.funny !=0]\n",
    "final_df = final_df[final_df.cool !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Tracy dessert had a big name in Hong Kong and ...</td>\n",
       "      <td>['tracy', 'dessert', 'hong', 'kong', 'markham'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This place has gone down hill.  Clearly they h...</td>\n",
       "      <td>['place', 'gone', 'hill', 'clearly', 'staff', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>I love chinese food and I love mexican food. W...</td>\n",
       "      <td>['love', 'chinese', 'food', 'love', 'mexican',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9</td>\n",
       "      <td>If you are looking for the best pierogies in P...</td>\n",
       "      <td>['looking', 'best', 'pierogies', 'pittsburgh',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, I must recommend not to conduct...</td>\n",
       "      <td>['unfortunately', 'recommend', 'conduct', 'bus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    useful  funny  cool                                               text  \\\n",
       "6      5.0    4.0     5  Tracy dessert had a big name in Hong Kong and ...   \n",
       "7      3.0    1.0     1  This place has gone down hill.  Clearly they h...   \n",
       "17     1.0    7.0     1  I love chinese food and I love mexican food. W...   \n",
       "21     9.0    6.0     9  If you are looking for the best pierogies in P...   \n",
       "26     7.0    1.0     1  Unfortunately, I must recommend not to conduct...   \n",
       "\n",
       "                                               tokens  \n",
       "6   ['tracy', 'dessert', 'hong', 'kong', 'markham'...  \n",
       "7   ['place', 'gone', 'hill', 'clearly', 'staff', ...  \n",
       "17  ['love', 'chinese', 'food', 'love', 'mexican',...  \n",
       "21  ['looking', 'best', 'pierogies', 'pittsburgh',...  \n",
       "26  ['unfortunately', 'recommend', 'conduct', 'bus...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11904, 5)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(index=True)\n",
    "final_df.to_csv(r'final_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep: \n",
    "\n",
    "**Description**: \n",
    "\n",
    "Combining based on their *Unique Account ID's.*\n",
    "The end Product will be One DataFrame Consisting of Each Account:\n",
    "- **Name**, \n",
    "- **User_ID**,\n",
    "- **Review_ID**,\n",
    "- **Text**,\n",
    "- **That Users respective review(s)**,\n",
    "- **Interactions that Review (i.e: Cool, Funny, Useful)**  \n",
    "\n",
    "The goal of the model is to have the ability to type in the Review you are wanting to post on Yelp, and give the User the ability to Predict What type of Interaction they would potentially receive and Total Number of each interaction. The model Accuracy will be Displayed beside the Prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports: \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Variables for Training \n",
    "interactions1 = final_df['useful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Dataset into training and test set\n",
    "\n",
    "    # Using 10,000 Rows. \n",
    "\n",
    "reviews = final_df['text'].iloc[0:10000]\n",
    "interactions1 = interactions1.iloc[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on TF-IDF Vectors\n",
    "nn  = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining\n",
    "# tokenizer\n",
    "def tokenize(document):\n",
    "    doc = nlp(document)\n",
    "    return [token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True)]\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=0.025, max_df=.95, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Fake Review for Testing: \n",
    "fake_review = \"\"\"\n",
    "After finshing our dinner we heard a loud crash come from the back of the place The next thing we saw was a cook running out of the kitchen chasing a cat with a cleaver covered in blood and animal hair... My children were traumatized.. Given that the cat looked exactly like Whiskers, who ran away last week. \n",
    "I had no idea how I was going to parent that situation given that I was completley drunk and could not stop laughing. The beer was a little flat, the 'chicken' was a little gamey. \n",
    "Service was great 4 Stars.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "vect_review = tfidf.fit_transform(tokenize(fake_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haden/anaconda3/envs/ydc1/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.75, 1.0), 'vect__min_df': (0.02, 0.05), 'vect__max_features': (500, 1000), 'clf__n_estimators': (5, 10), 'clf__max_depth': (15, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Pipeline Components\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect', vect), \n",
    "                 # Classifier\n",
    "                 ('clf', rfc)\n",
    "                ])\n",
    "\n",
    "\n",
    "#Tuning\n",
    "parameters = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'vect__min_df': (.02, 0.05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators':(5, 10,),\n",
    "    'clf__max_depth':(15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs= -1, verbose=1)\n",
    "grid_search.fit(reviews, interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5387"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 15,\n",
       " 'clf__n_estimators': 10,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': 500,\n",
       " 'vect__min_df': 0.02}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "# Fake Review Interaction 'Useful' Prediction: \n",
    "\n",
    "useful_pred = grid_search.predict([r'vect_review'])\n",
    "print(useful_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['useful_clf.joblib']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pickling Model with JobLib\n",
    "joblib.dump(useful_pred, 'useful_clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Fake Review for Testing: \n",
    "fake_review2 = \"\"\"Big props to Joseph at the drive-thru window for really representing the Starbucks brand well and pushing for app downloads.\n",
    "He makes for a great brand ambassador! Expect long lines in the drive-through but friendly service. I was surprised and curious to see the sous vide egg and bacon option now on the menu. Located along capital Avenue on your way to downtown the spot seems to be quite popular for those grabbing a coffee before heading into the office.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "vect_review3 = tfidf.fit_transform(tokenize(fake_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "useful_pred2 = grid_search.predict([r'vect_review2'])\n",
    "print(useful_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "vect_review2 = tfidf.fit_transform(tokenize(final_df['text'].iloc[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "useful_pred2 = grid_search.predict([r'vect_review2'])\n",
    "print(useful_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's why I don't write reviews for Chinese restaurants: I have to look up their English names... It's so popular that I didn't try it until recently. The bubble tea here is really good. It's pricier than the one in Rose tea, but you also get more. I like that noodles with pork sauce. I've tried both the thin and wide/thick noodles. The wide one is less chewy and are kind of sticky. I prefer the thin one for this dish.Dan dan noodles are different from what I was expecting. My friend liked it but it's just okay for me.The noodle with wonton is flavorless to me. The soup dumplings are good but not amazing. If you've never had it before, give it a try and you probably will like it.I'd like to try noodles with beef soup next time.The appetizers are too pricy in my opinion. I won't pay $6 for a small plate of vegetables again...The owner is a nice guy and I enjoyed chatting with him a little bit during dinners.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['text'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "useful                                                    7\n",
       "funny                                                     0\n",
       "cool                                                      0\n",
       "text      Today was my second out of three sessions I ha...\n",
       "tokens    ['today', 'second', 'sessions', 'paid', 'sessi...\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW Model Prep: As of 1/08/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Unwanted Columns\n",
    "#final_df = final.drop(columns=['Unnamed: 0', 'user_id', 'review_id', 'date'])\n",
    "# Final_df.csv File was too Large. Cutting Down to First 95,000 Rows.\n",
    "final_df = final_df.iloc[0:95000]\n",
    "\n",
    "# Save Cleaned and Trimmed final_df.csv \n",
    "final_df.to_csv(index=True)\n",
    "final_df.to_csv(r'final_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = dtm_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95000, 773)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_final = dtm.iloc[0:95000]\n",
    "# Save Trimmed dtm_final.csv \n",
    "dtm_final.to_csv(index=True)\n",
    "dtm_final.to_csv(r'dtm_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95000, 773)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Random Forest Regression Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "# import Vectorizer Model\n",
    "#vect = joblib.load('vect_2.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = final_df[['useful', 'funny', 'cool']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Dataset into training and test set\n",
    "X = dtm_final\n",
    "y = interactions\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Regression to Dataset\n",
    "regressor = RandomForestRegressor(n_estimators = 15, random_state = 0)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regressor.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pickling Model with JobLib\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(regressor, 'regressor.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Model \n",
    "regressor = joblib.load('regressor.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Fake Review for Testing: \n",
    "fake_review = \"\"\"\n",
    "After finshing our dinner, we heard a loud crash come from the back of the place. The next thing we saw was a cook running out of the kitchen chasing a cat with a cleaver covered in blood and animal hair... My children were traumatized.. Given that the cat looked exactly like Whiskers, who ran away last week. \n",
    "I had no idea how I was going to parent that situation, given that I was completley drunk and could not stop laughing. The beer was a little flat, the chicken was a little gamey. \n",
    "Service was great though. four Stars.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_pred = regressor.predict(fake_review)\n",
    "print(fake_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Different Regressor: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Using ONE Interaction: \n",
    "interactions2 = final_df['useful']\n",
    "\n",
    "# Splitting Dataset into training and test set\n",
    "X = dtm_final\n",
    "y = interactions2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Regression to Dataset\n",
    "regressor2 = RandomForestRegressor(n_estimators = 5, random_state = 0)\n",
    "regressor2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Fake Review for Testing: \n",
    "fake_review = [\"\"\"\n",
    "After finshing our dinner, we heard a loud crash come from the back of the place. The next thing we saw was a cook running out of the kitchen chasing a cat with a cleaver covered in blood and animal hair... My children were traumatized.. Given that the cat looked exactly like Whiskers, who ran away last week. \n",
    "I had no idea how I was going to parent that situation, given that I was completley drunk and could not stop laughing. The beer was a little flat, the chicken was a little gamey. \n",
    "Service was great though. 4 Stars.\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "vect_review = tfidf.fit_transform(tokenize(fake_review))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ydc1] *",
   "language": "python",
   "name": "conda-env-ydc1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
