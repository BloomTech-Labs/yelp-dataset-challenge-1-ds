{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Up: \n",
    "Before Running the cell below, you must ensure that these have been run in Terminal **IN ORDER** : \n",
    "- conda update -n base -c defaults conda \n",
    "\n",
    "    - cd SageMaker\n",
    "    \n",
    "      - cd yelp-dataset-challenge-1-ds\n",
    "      \n",
    "         - conda env create -f environment.yml\n",
    "          \n",
    "            - source activate ydc1 \n",
    "                \n",
    "                - pip install python-decouple\n",
    "                  \n",
    "                  - pip install pprintpp\n",
    "                  \n",
    "# Spacy Installs: \n",
    "\n",
    "   - python -m spacy download en_core_web_lg\n",
    "\n",
    "        - python -m spacy link en_core_web_lg en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "#import s3\n",
    "#from pprintpp import pprint as pp\n",
    "from sklearn.externals import joblib\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# Load in Bucket\n",
    "#bucket = s3.Bucket('yelpchallenge1')\n",
    "# Look inside the bucket.\n",
    "#bucket.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    ### ***** DO NOT RUN. ******* #### \n",
    "                  ### ***** ALREADY INSTALLED. ****** ###\n",
    "\n",
    "# Only have to run this once.\n",
    "# Installs the .csv 'Locally' on SageMaker Instance\n",
    "\n",
    "#bucket.get('datasets/df.csv', 'df.csv')\n",
    "\n",
    "# Installing user.json 'Locally'\n",
    "#bucket.get('datasets/user.json', 'user.json')\n",
    "\n",
    "\n",
    "    # Load in Bucket\n",
    "# bucket = s3.Bucket('yelpchallenge1')\n",
    "    # Look inside the bucket.\n",
    "# bucket.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Read-in final.csv\n",
    "final_df = pd.read_csv('final_df.csv')\n",
    "\n",
    "    # Read-in df.csv\n",
    "#df = pd.read_csv('df.csv', nrows=250000)\n",
    "\n",
    "\n",
    "    # Read-in review_df.csv\n",
    "#review_df = pd.read_csv('review.csv')\n",
    "\n",
    "    # Read-in dtm_final.csv (FINAL)\n",
    "#dtm_final = pd.read_csv('dtm_final.csv')\n",
    "\n",
    "    # import Vectorizer Model\n",
    "#vect2 = joblib.load('vect_2.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON- -PRON-</th>\n",
       "      <th>-PRON- a</th>\n",
       "      <th>-PRON- all</th>\n",
       "      <th>-PRON- also</th>\n",
       "      <th>-PRON- and</th>\n",
       "      <th>...</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>would be</th>\n",
       "      <th>would have</th>\n",
       "      <th>would not</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yet</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.343331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.314034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.080641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.515313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02601</td>\n",
       "      <td>0.027762</td>\n",
       "      <td>0.021839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028812</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1    -PRON-  -PRON-    \\\n",
       "0           0             0               0  0.069829       0.0   \n",
       "1           1             1               1  0.343331       0.0   \n",
       "2           2             2               2  0.314034       0.0   \n",
       "3           3             3               3  0.080641       0.0   \n",
       "4           4             4               4  0.515313       0.0   \n",
       "\n",
       "   -PRON- -PRON-  -PRON- a  -PRON- all  -PRON- also  -PRON- and  ...  \\\n",
       "0       0.000000       0.0         0.0          0.0    0.000000  ...   \n",
       "1       0.000000       0.0         0.0          0.0    0.047998  ...   \n",
       "2       0.000000       0.0         0.0          0.0    0.000000  ...   \n",
       "3       0.000000       0.0         0.0          0.0    0.000000  ...   \n",
       "4       0.020392       0.0         0.0          0.0    0.043038  ...   \n",
       "\n",
       "      worth     would  would be  would have  would not     wrong      year  \\\n",
       "0  0.000000  0.000000       0.0         0.0    0.00000  0.000000  0.000000   \n",
       "1  0.052035  0.000000       0.0         0.0    0.00000  0.000000  0.000000   \n",
       "2  0.000000  0.000000       0.0         0.0    0.00000  0.000000  0.093163   \n",
       "3  0.000000  0.087372       0.0         0.0    0.00000  0.000000  0.000000   \n",
       "4  0.000000  0.029004       0.0         0.0    0.02601  0.027762  0.021839   \n",
       "\n",
       "   yelp       yet  stars  \n",
       "0   0.0  0.000000    1.0  \n",
       "1   0.0  0.000000    5.0  \n",
       "2   0.0  0.000000    5.0  \n",
       "3   0.0  0.000000    5.0  \n",
       "4   0.0  0.028812    1.0  \n",
       "\n",
       "[5 rows x 777 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_final = dtm_final.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_final = dtm_final.drop(columns = ['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON- -PRON-</th>\n",
       "      <th>-PRON- a</th>\n",
       "      <th>-PRON- all</th>\n",
       "      <th>-PRON- also</th>\n",
       "      <th>-PRON- and</th>\n",
       "      <th>-PRON- be</th>\n",
       "      <th>-PRON- but</th>\n",
       "      <th>-PRON- can</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>would be</th>\n",
       "      <th>would have</th>\n",
       "      <th>would not</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     -PRON-  -PRON-    -PRON- -PRON-  -PRON- a  -PRON- all  -PRON- also  \\\n",
       "0  0.069829       0.0            0.0       0.0         0.0          0.0   \n",
       "\n",
       "   -PRON- and  -PRON- be  -PRON- but  -PRON- can  ...  work  worth  would  \\\n",
       "0         0.0        0.0         0.0         0.0  ...   0.0    0.0    0.0   \n",
       "\n",
       "   would be  would have  would not  wrong  year  yelp  yet  \n",
       "0       0.0         0.0        0.0    0.0   0.0   0.0  0.0  \n",
       "\n",
       "[1 rows x 773 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_final.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95000, 773)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['useful', 'funny', 'cool', 'text', 'tokens'], dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping All Rows with 0 in Interactions Column \n",
    "final_df = final_df[final_df.useful !=0]\n",
    "final_df = final_df[final_df.funny !=0]\n",
    "final_df = final_df[final_df.cool !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Tracy dessert had a big name in Hong Kong and ...</td>\n",
       "      <td>['tracy', 'dessert', 'hong', 'kong', 'markham'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>This place has gone down hill.  Clearly they h...</td>\n",
       "      <td>['place', 'gone', 'hill', 'clearly', 'staff', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>I love chinese food and I love mexican food. W...</td>\n",
       "      <td>['love', 'chinese', 'food', 'love', 'mexican',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>If you are looking for the best pierogies in P...</td>\n",
       "      <td>['looking', 'best', 'pierogies', 'pittsburgh',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, I must recommend not to conduct...</td>\n",
       "      <td>['unfortunately', 'recommend', 'conduct', 'bus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  useful  funny  cool  \\\n",
       "0           6       5      4     5   \n",
       "1           7       3      1     1   \n",
       "2          17       1      7     1   \n",
       "3          21       9      6     9   \n",
       "4          26       7      1     1   \n",
       "\n",
       "                                                text  \\\n",
       "0  Tracy dessert had a big name in Hong Kong and ...   \n",
       "1  This place has gone down hill.  Clearly they h...   \n",
       "2  I love chinese food and I love mexican food. W...   \n",
       "3  If you are looking for the best pierogies in P...   \n",
       "4  Unfortunately, I must recommend not to conduct...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['tracy', 'dessert', 'hong', 'kong', 'markham'...  \n",
       "1  ['place', 'gone', 'hill', 'clearly', 'staff', ...  \n",
       "2  ['love', 'chinese', 'food', 'love', 'mexican',...  \n",
       "3  ['looking', 'best', 'pierogies', 'pittsburgh',...  \n",
       "4  ['unfortunately', 'recommend', 'conduct', 'bus...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(final_df['useful'].dtype)\n",
    "print(final_df['funny'].dtype)\n",
    "print(final_df['cool'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting columns with Dtypes Float64 to Int64 \n",
    "final_df['useful'] = final_df['useful'].astype('Float64')\n",
    "final_df['funny'] = final_df['funny'].astype('Float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(final_df['useful'].dtype)\n",
    "print(final_df['funny'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Tracy dessert had a big name in Hong Kong and ...</td>\n",
       "      <td>['tracy', 'dessert', 'hong', 'kong', 'markham'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This place has gone down hill.  Clearly they h...</td>\n",
       "      <td>['place', 'gone', 'hill', 'clearly', 'staff', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>I love chinese food and I love mexican food. W...</td>\n",
       "      <td>['love', 'chinese', 'food', 'love', 'mexican',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9</td>\n",
       "      <td>If you are looking for the best pierogies in P...</td>\n",
       "      <td>['looking', 'best', 'pierogies', 'pittsburgh',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, I must recommend not to conduct...</td>\n",
       "      <td>['unfortunately', 'recommend', 'conduct', 'bus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  useful  funny  cool  \\\n",
       "0           6     5.0    4.0     5   \n",
       "1           7     3.0    1.0     1   \n",
       "2          17     1.0    7.0     1   \n",
       "3          21     9.0    6.0     9   \n",
       "4          26     7.0    1.0     1   \n",
       "\n",
       "                                                text  \\\n",
       "0  Tracy dessert had a big name in Hong Kong and ...   \n",
       "1  This place has gone down hill.  Clearly they h...   \n",
       "2  I love chinese food and I love mexican food. W...   \n",
       "3  If you are looking for the best pierogies in P...   \n",
       "4  Unfortunately, I must recommend not to conduct...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['tracy', 'dessert', 'hong', 'kong', 'markham'...  \n",
       "1  ['place', 'gone', 'hill', 'clearly', 'staff', ...  \n",
       "2  ['love', 'chinese', 'food', 'love', 'mexican',...  \n",
       "3  ['looking', 'best', 'pierogies', 'pittsburgh',...  \n",
       "4  ['unfortunately', 'recommend', 'conduct', 'bus...  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Tracy dessert had a big name in Hong Kong and ...</td>\n",
       "      <td>['tracy', 'dessert', 'hong', 'kong', 'markham'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   useful  funny  cool                                               text  \\\n",
       "0     5.0    4.0     5  Tracy dessert had a big name in Hong Kong and ...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['tracy', 'dessert', 'hong', 'kong', 'markham'...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(index=True)\n",
    "final_df.to_csv(r'final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = dtm_final.iloc[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON- -PRON-</th>\n",
       "      <th>-PRON- a</th>\n",
       "      <th>-PRON- all</th>\n",
       "      <th>-PRON- also</th>\n",
       "      <th>-PRON- and</th>\n",
       "      <th>-PRON- be</th>\n",
       "      <th>-PRON- but</th>\n",
       "      <th>-PRON- can</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>would be</th>\n",
       "      <th>would have</th>\n",
       "      <th>would not</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.343331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047998</td>\n",
       "      <td>0.122973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.314034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.080641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.515313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.027566</td>\n",
       "      <td>0.028836</td>\n",
       "      <td>0.020320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02601</td>\n",
       "      <td>0.027762</td>\n",
       "      <td>0.021839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     -PRON-  -PRON-    -PRON- -PRON-  -PRON- a  -PRON- all  -PRON- also  \\\n",
       "0  0.069829       0.0       0.000000       0.0         0.0          0.0   \n",
       "1  0.343331       0.0       0.000000       0.0         0.0          0.0   \n",
       "2  0.314034       0.0       0.000000       0.0         0.0          0.0   \n",
       "3  0.080641       0.0       0.000000       0.0         0.0          0.0   \n",
       "4  0.515313       0.0       0.020392       0.0         0.0          0.0   \n",
       "\n",
       "   -PRON- and  -PRON- be  -PRON- but  -PRON- can  ...      work     worth  \\\n",
       "0    0.000000   0.000000    0.000000    0.000000  ...  0.000000  0.000000   \n",
       "1    0.047998   0.122973    0.000000    0.000000  ...  0.000000  0.052035   \n",
       "2    0.000000   0.039198    0.000000    0.086683  ...  0.084567  0.000000   \n",
       "3    0.000000   0.110721    0.000000    0.000000  ...  0.000000  0.000000   \n",
       "4    0.043038   0.027566    0.028836    0.020320  ...  0.000000  0.000000   \n",
       "\n",
       "      would  would be  would have  would not     wrong      year  yelp  \\\n",
       "0  0.000000       0.0         0.0    0.00000  0.000000  0.000000   0.0   \n",
       "1  0.000000       0.0         0.0    0.00000  0.000000  0.000000   0.0   \n",
       "2  0.000000       0.0         0.0    0.00000  0.000000  0.093163   0.0   \n",
       "3  0.087372       0.0         0.0    0.00000  0.000000  0.000000   0.0   \n",
       "4  0.029004       0.0         0.0    0.02601  0.027762  0.021839   0.0   \n",
       "\n",
       "        yet  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.028812  \n",
       "\n",
       "[5 rows x 773 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep: \n",
    "\n",
    "**Description**: \n",
    "\n",
    "Combining based on their *Unique Account ID's.*\n",
    "The end Product will be One DataFrame Consisting of Each Account:\n",
    "- **Name**, \n",
    "- **User_ID**,\n",
    "- **Review_ID**,\n",
    "- **Text**,\n",
    "- **That Users respective review(s)**,\n",
    "- **Interactions that Review (i.e: Cool, Funny, Useful)**  \n",
    "\n",
    "The goal of the model is to have the ability to type in the Review you are wanting to post on Yelp, and give the User the ability to Predict What type of Interaction they would potentially receive and Total Number of each interaction. The model Accuracy will be Displayed beside the Prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports: \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Variables for Training \n",
    "interactions1 = final_df['useful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Dataset into training sets\n",
    "\n",
    "    # Using 10,000 Rows. \n",
    "\n",
    "reviews = final_df['text'].iloc[0:10000]\n",
    "interactions1 = interactions1.iloc[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on TF-IDF Vectors\n",
    "nn  = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining\n",
    "# tokenizer\n",
    "def tokenize(document):\n",
    "    doc = nlp(document)\n",
    "    return [token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True)]\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=0.025, max_df=.95, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Fake Review for Testing: \n",
    "fake_review = \"\"\"\n",
    "After finshing our dinner we heard a loud crash come from the back of the place The next thing we saw was a cook running out of the kitchen chasing a cat with a cleaver covered in blood and animal hair... My children were traumatized.. Given that the cat looked exactly like Whiskers, who ran away last week. \n",
    "I had no idea how I was going to parent that situation given that I was completley drunk and could not stop laughing. The beer was a little flat, the 'chicken' was a little gamey. \n",
    "Service was great 4 Stars.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "vect_review = tfidf.fit_transform(tokenize(fake_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haden/anaconda3/envs/ydc1/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.75, 1.0), 'vect__min_df': (0.02, 0.05), 'vect__max_features': (500, 1000), 'clf__n_estimators': (5, 10), 'clf__max_depth': (15, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Pipeline Components\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect', vect), \n",
    "                 # Classifier\n",
    "                 ('clf', rfc)\n",
    "                ])\n",
    "\n",
    "\n",
    "#Tuning\n",
    "parameters = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'vect__min_df': (.02, 0.05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators':(5, 10,),\n",
    "    'clf__max_depth':(15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs= -1, verbose=1)\n",
    "grid_search.fit(reviews, interaction1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5387"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 15,\n",
       " 'clf__n_estimators': 10,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': 500,\n",
       " 'vect__min_df': 0.02}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "# Fake Review Interaction 'Useful' Prediction: \n",
    "\n",
    "useful_pred = grid_search.predict([r'vect_review'])\n",
    "print(useful_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['useful_clf.joblib']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pickling Model with JobLib\n",
    "joblib.dump(useful_pred, 'useful_clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Fake Review for Testing: \n",
    "fake_review4 = \"\"\"\n",
    "After finshing our dinner we heard a loud crash come from the back of the place The next thing we saw was a cook running out of the kitchen chasing a cat with a cleaver covered in blood and animal hair... My children were traumatized.. Given that the cat looked exactly like Whiskers, who ran away last week. \n",
    "I had no idea how I was going to parent that situation given that I was completley drunk and could not stop laughing. The beer was a little flat, the 'chicken' was a little gamey. \n",
    "Service was great 4 Stars.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing Fake_Review4\n",
    "vect_review4 = tfidf.fit_transform(tokenize(fake_review4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "useful_pred4 = grid_search.predict([r'vect_review4'])\n",
    "print(useful_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "vect_review2 = tfidf.fit_transform(tokenize(fake_review2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "useful_pred2 = grid_search.predict([r'vect_review2'])\n",
    "print(useful_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's why I don't write reviews for Chinese restaurants: I have to look up their English names... It's so popular that I didn't try it until recently. The bubble tea here is really good. It's pricier than the one in Rose tea, but you also get more. I like that noodles with pork sauce. I've tried both the thin and wide/thick noodles. The wide one is less chewy and are kind of sticky. I prefer the thin one for this dish.Dan dan noodles are different from what I was expecting. My friend liked it but it's just okay for me.The noodle with wonton is flavorless to me. The soup dumplings are good but not amazing. If you've never had it before, give it a try and you probably will like it.I'd like to try noodles with beef soup next time.The appetizers are too pricy in my opinion. I won't pay $6 for a small plate of vegetables again...The owner is a nice guy and I enjoyed chatting with him a little bit during dinners.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['text'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "useful                                                    7\n",
       "funny                                                     0\n",
       "cool                                                      0\n",
       "text      Today was my second out of three sessions I ha...\n",
       "tokens    ['today', 'second', 'sessions', 'paid', 'sessi...\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5405"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropped all 0's from Rows \n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 15,\n",
       " 'clf__n_estimators': 10,\n",
       " 'vect__max_df': 0.75,\n",
       " 'vect__max_features': 500,\n",
       " 'vect__min_df': 0.05}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Fake Review5 for Testing: \n",
    "fake_review5 = \"\"\"\n",
    "After finshing our dinner we heard a loud crash come from the back of the place The next thing we saw was a cook running out of the kitchen chasing a cat with a cleaver covered in blood and animal hair... My children were traumatized.. Given that the cat looked exactly like Whiskers, who ran away last week. \n",
    "I had no idea how I was going to parent that situation given that I was completley drunk and could not stop laughing. The beer was a little flat, the 'chicken' was a little gamey. \n",
    "Service was great 4 Stars.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing Fake_Review5\n",
    "vect_review5 = tfidf.fit_transform(tokenize(fake_review5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "# Fake Review Interaction 'Useful' Prediction: \n",
    "\n",
    "useful_pred5 = grid_search.predict([r'vect_review5'])\n",
    "print(useful_pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still getting 0...... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "# Testing with a Randomly pulled Review from Final_df for tokenization and prediction. \n",
    "review_888 = final_df['text'].iloc[888]\n",
    "# Interaction 'Useful' Prediction: \n",
    "vect_review6 = tfidf.fit_transform(tokenize(review_888))\n",
    "useful_pred6 = grid_search.predict([r'vect_review6'])\n",
    "print(useful_pred6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier after Changes: as of 1/09/2020 at 7:00PM EST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports: \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Variables for Training \n",
    "interactions = final_df['funny']\n",
    "\n",
    "# Splitting Dataset into training sets\n",
    "\n",
    "    # Using 10,000 Rows. \n",
    "\n",
    "reviews = final_df['text'].iloc[0:10000]\n",
    "interactions = interactions.iloc[0:10000]\n",
    "\n",
    "# Fit on TF-IDF Vectors\n",
    "nn  = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "nn.fit(dtm)\n",
    "\n",
    "# Defining\n",
    "# tokenizer\n",
    "def tokenize(document):\n",
    "    doc = nlp(document)\n",
    "    return [token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True)]\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=0.025, max_df=.95, ngram_range=(1,2))\n",
    "\n",
    "\n",
    "# Creating Fake Review for Testing: \n",
    "fake_review = \"\"\"\n",
    "After finshing our dinner we heard a loud crash come from the back of the place The next thing we saw was a cook running out of the kitchen chasing a cat with a cleaver covered in blood and animal hair... My children were traumatized.. Given that the cat looked exactly like Whiskers, who ran away last week. \n",
    "I had no idea how I was going to parent that situation given that I was completley drunk and could not stop laughing. The beer was a little flat, the 'chicken' was a little gamey. \n",
    "Service was great 4 Stars.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "vect_review1 = tfidf.fit_transform(tokenize(fake_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haden/anaconda3/envs/ydc1/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.75, 1.0), 'vect__min_df': (0.02, 0.05), 'vect__max_features': (500, 1000), 'clf__n_estimators': (5, 10), 'clf__max_depth': (15, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Pipeline Components\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect', vect), \n",
    "                 # Classifier\n",
    "                 ('clf', rfc)\n",
    "                ])\n",
    "\n",
    "\n",
    "#Tuning\n",
    "parameters = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'vect__min_df': (.02, 0.05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators':(5, 10,),\n",
    "    'clf__max_depth':(15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs= -1, verbose=1)\n",
    "grid_search.fit(reviews, interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5166\n",
      "{'clf__max_depth': 15, 'clf__n_estimators': 10, 'vect__max_df': 0.75, 'vect__max_features': 1000, 'vect__min_df': 0.02}\n"
     ]
    }
   ],
   "source": [
    "# Score\n",
    "print(grid_search.best_score_) \n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "# Fake Review Interaction 'Cool' Prediction: \n",
    "\n",
    "cool_pred = grid_search.predict([r'vect_review1'])\n",
    "print(cool_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Random Forest Regression Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "# import Vectorizer Model\n",
    "#vect = joblib.load('vect_2.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = final_df[['useful', 'funny', 'cool']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Dataset into training and test set\n",
    "X = dtm_final\n",
    "y = interactions\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Regression to Dataset\n",
    "regressor = RandomForestRegressor(n_estimators = 15, random_state = 0)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regressor.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pickling Model with JobLib\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(regressor, 'regressor.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Model \n",
    "regressor = joblib.load('regressor.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Fake Review for Testing: \n",
    "fake_review = \"\"\"\n",
    "After finshing our dinner, we heard a loud crash come from the back of the place. The next thing we saw was a cook running out of the kitchen chasing a cat with a cleaver covered in blood and animal hair... My children were traumatized.. Given that the cat looked exactly like Whiskers, who ran away last week. \n",
    "I had no idea how I was going to parent that situation, given that I was completley drunk and could not stop laughing. The beer was a little flat, the chicken was a little gamey. \n",
    "Service was great though. four Stars.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_pred = regressor.predict(fake_review)\n",
    "print(fake_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Different Regressor: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Using ONE Interaction: \n",
    "interactions2 = final_df['useful']\n",
    "\n",
    "# Splitting Dataset into training and test set\n",
    "X = dtm_final\n",
    "y = interactions2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Regression to Dataset\n",
    "regressor2 = RandomForestRegressor(n_estimators = 5, random_state = 0)\n",
    "regressor2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Fake Review for Testing: \n",
    "fake_review = [\"\"\"\n",
    "After finshing our dinner, we heard a loud crash come from the back of the place. The next thing we saw was a cook running out of the kitchen chasing a cat with a cleaver covered in blood and animal hair... My children were traumatized.. Given that the cat looked exactly like Whiskers, who ran away last week. \n",
    "I had no idea how I was going to parent that situation, given that I was completley drunk and could not stop laughing. The beer was a little flat, the chicken was a little gamey. \n",
    "Service was great though. 4 Stars.\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "vect_review = tfidf.fit_transform(tokenize(fake_review))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ydc1] *",
   "language": "python",
   "name": "conda-env-ydc1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
