{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing New csv Load In Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must Pip Install python-decouple each time. \n",
    "#!pip install python-decouple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a Progress Bar Install for the Vectorizer. \n",
    "#import pyprind\n",
    "#import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#import theano\n",
    "import spacy\n",
    "import s3\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everytime you enter\n",
    "bucket = s3.Bucket('yelpchallenge1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/',\n",
       " 'datasets/df.csv',\n",
       " 'notebooks/',\n",
       " 'notebooks/data_cleanup.ipynb',\n",
       " 'notebooks/vectorization_exploration.ipynb',\n",
       " 'notebooks/yelp_data_initial_exploration.ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look inside the bucket.\n",
    "bucket.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only have to run this once.\n",
    "# Installs the .csv 'Locally' on SageMaker Instance\n",
    "\n",
    "#bucket.get('datasets/df.csv', 'df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/ydc1/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read df.csv\n",
    "# Time to Load In: 8 Minutes.... \n",
    "df = pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>['total', 'horrible', 'service', 'crooks', 'ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['adore', 'travis', 'hard', 'rock', 'kelly', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['office', 'organized', 'friendly', 'phillipp'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['went', 'lunch', 'steak', 'sandwich', 'delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>7.0</td>\n",
       "      <td>['today', 'second', 'sessions', 'paid', 'sessi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 stars                                               text  \\\n",
       "0          0     1  Total bill for this horrible service? Over $8G...   \n",
       "1          1     5  I *adore* Travis at the Hard Rock's new Kelly ...   \n",
       "2          2     5  I have to say that this office really has it t...   \n",
       "3          3     5  Went in for a lunch. Steak sandwich was delici...   \n",
       "4          4     1  Today was my second out of three sessions I ha...   \n",
       "\n",
       "                  date  total_votes  \\\n",
       "0  2013-05-07 04:34:36          7.0   \n",
       "1  2017-01-14 21:30:33          0.0   \n",
       "2  2016-11-09 20:09:03          3.0   \n",
       "3  2018-01-09 20:56:38          0.0   \n",
       "4  2018-01-30 23:07:38          7.0   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['total', 'horrible', 'service', 'crooks', 'ac...  \n",
       "1  ['adore', 'travis', 'hard', 'rock', 'kelly', '...  \n",
       "2  ['office', 'organized', 'friendly', 'phillipp'...  \n",
       "3  ['went', 'lunch', 'steak', 'sandwich', 'delici...  \n",
       "4  ['today', 'second', 'sessions', 'paid', 'sessi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check import\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      object\n",
       "stars           object\n",
       "text            object\n",
       "date            object\n",
       "total_votes    float64\n",
       "tokens          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes of columns in dataframe\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unwanted columns\n",
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>['total', 'horrible', 'service', 'crooks', 'ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['adore', 'travis', 'hard', 'rock', 'kelly', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['office', 'organized', 'friendly', 'phillipp'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['went', 'lunch', 'steak', 'sandwich', 'delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>7.0</td>\n",
       "      <td>['today', 'second', 'sessions', 'paid', 'sessi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stars                                               text  \\\n",
       "0     1  Total bill for this horrible service? Over $8G...   \n",
       "1     5  I *adore* Travis at the Hard Rock's new Kelly ...   \n",
       "2     5  I have to say that this office really has it t...   \n",
       "3     5  Went in for a lunch. Steak sandwich was delici...   \n",
       "4     1  Today was my second out of three sessions I ha...   \n",
       "\n",
       "                  date  total_votes  \\\n",
       "0  2013-05-07 04:34:36          7.0   \n",
       "1  2017-01-14 21:30:33          0.0   \n",
       "2  2016-11-09 20:09:03          3.0   \n",
       "3  2018-01-09 20:56:38          0.0   \n",
       "4  2018-01-30 23:07:38          7.0   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['total', 'horrible', 'service', 'crooks', 'ac...  \n",
       "1  ['adore', 'travis', 'hard', 'rock', 'kelly', '...  \n",
       "2  ['office', 'organized', 'friendly', 'phillipp'...  \n",
       "3  ['went', 'lunch', 'steak', 'sandwich', 'delici...  \n",
       "4  ['today', 'second', 'sessions', 'paid', 'sessi...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars           object\n",
       "text            object\n",
       "date            object\n",
       "total_votes    float64\n",
       "tokens          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6876898, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mini-dataframe for testing\n",
    "# want to make sure works locally on small dataset before scaling to entire dataset/AWS\n",
    "#mini_df = df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new tokenizer\n",
    "def tokenize(document):\n",
    "    doc = nlp(document)\n",
    "    return [token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable to feed into TFIDF Vectorizer fit_transform\n",
    "# to be updated to 'text' column of main dataframe (df['text']) for vectorization in AWS\n",
    "data = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Total bill for this horrible service? Over $8G...\n",
       "1    I *adore* Travis at the Hard Rock's new Kelly ...\n",
       "2    I have to say that this office really has it t...\n",
       "3    Went in for a lunch. Steak sandwich was delici...\n",
       "4    Today was my second out of three sessions I ha...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6876898,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131090"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values/ Before Drop.nas\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping na from Data\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BEGONE NON-EXISTENT DATA\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6745808,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I have to say that this office really has it together, they are so organized and friendly!  Dr. J. Phillipp is a great dentist, very friendly and professional.  The dental assistants that helped in my procedure were amazing, Jewel and Bailey helped me to feel comfortable!  I don't have dental insurance, but they have this insurance through their office you can purchase for $80 something a year and this gave me 25% off all of my dental work, plus they helped me get signed up for care credit which I knew nothing about before this visit!  I highly recommend this office for the nice synergy the whole office has!\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=0.025, max_df=.95, ngram_range=(1,2))\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "# Learn vocab and transform data into form we want\n",
    "\n",
    "    # Started at 7:09 PM / 11-24-19\n",
    "    # data_1 has 3,372,904 rows\n",
    "\n",
    "# sparse = tfidf.fit_transform(data_1)\n",
    "\n",
    "# Print word counts\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "\n",
    "#dtm = pd.DataFrame(sparse.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "\n",
    "#dtm.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6745808,)\n",
      "0          Total bill for this horrible service? Over $8G...\n",
      "1          I *adore* Travis at the Hard Rock's new Kelly ...\n",
      "2          I have to say that this office really has it t...\n",
      "3          Went in for a lunch. Steak sandwich was delici...\n",
      "4          Today was my second out of three sessions I ha...\n",
      "5          I'll be the first to admit that I was not exci...\n",
      "6          Tracy dessert had a big name in Hong Kong and ...\n",
      "7          This place has gone down hill.  Clearly they h...\n",
      "8          I was really looking forward to visiting after...\n",
      "9          It's a giant Best Buy with 66 registers.  I do...\n",
      "10         Like walking back in time, every Saturday morn...\n",
      "11         Walked in around 4 on a Friday afternoon, we s...\n",
      "12         Wow. So surprised at the one and two star revi...\n",
      "13         Michael from Red Carpet VIP is amazing ! I rea...\n",
      "14         I cannot believe how things have changed in 3 ...\n",
      "15         You can't really find anything wrong with this...\n",
      "16         Great lunch today. Staff was very helpful in a...\n",
      "17         I love chinese food and I love mexican food. W...\n",
      "18         We've been a huge Slim's fan since they opened...\n",
      "19         Good selection of classes of beers and mains. ...\n",
      "20         Our family LOVES the food here. Quick, friendl...\n",
      "21         If you are looking for the best pierogies in P...\n",
      "22         The food is always good and the prices are rea...\n",
      "23         Pick any meat on the planet and the chef will ...\n",
      "24         Great food, great service. Obviously fried chi...\n",
      "25         PlumbSmart provided superior service from begi...\n",
      "26         Unfortunately, I must recommend not to conduct...\n",
      "27         their pettuccine was fresh-made in the morning...\n",
      "28         if i can give this place no stars i would, i o...\n",
      "29         This review is in regards to our experience wa...\n",
      "                                 ...                        \n",
      "1817500    Normally I don't write less than positive revi...\n",
      "1817501    I always wanted to try Spago, so once we lande...\n",
      "1817502    This has got to be the slowest McDonalds in th...\n",
      "1817503    Updated review:I recently bought a suit, two s...\n",
      "1817504    Two stars because the manager gave me free mov...\n",
      "1817505    Only downside to this place is that they do no...\n",
      "1817506    While staying in Excalibur Hotel and Casino, w...\n",
      "1817507    Every meal here has been enjoyable and fantast...\n",
      "1817508    It's rare that I give a 3-star review, but my ...\n",
      "1817509    Went here with a friend and we both ordered tu...\n",
      "1817510    I was planning a day of shopping and needed to...\n",
      "1817511    Don't get me wrong the food here is as good as...\n",
      "1817512    I'm downtown, so to get here, it's a 20 min su...\n",
      "1817513    One word AMAZING!.  I am a steak lover I love ...\n",
      "1817514    The Tea Lab is the holy grail for tea lovers. ...\n",
      "1817515    By far the best wings in AZ! Try the Maple Hot...\n",
      "1817516    Decided to take my wife to Richardsons  after ...\n",
      "1817517    Having a feral colony is tough. Dr. A & staff ...\n",
      "1817518    Food wasn't that good fish n chips very soggy ...\n",
      "1817519    I liked the space, though I am sure it will be...\n",
      "1817520    We LOVE Metro Diner! Food is fantastic as is t...\n",
      "1817521    Super nice property! Awesome pool, great resta...\n",
      "1817522    Hannah is great. Wonderful service, love my na...\n",
      "1817523    Municipal Stadium was a magical place. I still...\n",
      "1817524    Had my downstairs carpet cleaned today (approx...\n",
      "1817525    We needed to have 3 ceiling fans installed and...\n",
      "1817526    We had prix fixe menu.  Most items were excell...\n",
      "1817527    I love the Cheesecake Factory food when I foun...\n",
      "1817528    Have been going here for years, shocked that n...\n",
      "1817529    My husband and I had a chance to see this show...\n",
      "Name: text, Length: 1686452, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Attempting to Break Up Data\n",
    "    # Breaking up data column into TWO Columns. \n",
    "        # data_1 & data_2 \n",
    "        # data_1 will have 3,372,904 rows. \n",
    "        # data_2 will have 3,372,905 rows. \n",
    "#\n",
    "print(data.shape)\n",
    "data_1 = data[0:1686452]\n",
    "data_2 = data[1686452]\n",
    "print(data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing PyStemmer instead of NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing a Progress Bar install for Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a Progress Bar Install for the Vectorizer.\n",
    "# Works pretty quickly..\n",
    "# Given that nothing is running.. HA! \n",
    "# Also a pointless feature that I spent 20 minutes on. . . \n",
    "\n",
    "#import pyprind\n",
    "#import psutil\n",
    "#import random\n",
    "#import time\n",
    "\n",
    "#n = 100\n",
    "#bar = pyprind.ProgBar(n, monitor=True)\n",
    "#for i in range(n):\n",
    "    #time.sleep(0.05)\n",
    "#tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=0.025, max_df=.95, ngram_range=(1,2))\n",
    "    #bar.update()\n",
    "#print(bar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_ydc1",
   "language": "python",
   "name": "conda_ydc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
