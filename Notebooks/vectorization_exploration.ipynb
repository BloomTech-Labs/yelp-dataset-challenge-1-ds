{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing New csv Load In Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import theano\n",
    "import spacy\n",
    "import s3\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everytime you enter\n",
    "bucket = s3.Bucket('yelpchallenge1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-11-19-21-16-41-90CA4F7C9BC5FF1F',\n",
       " '2019-11-19-21-16-52-6164438FEC3F364E',\n",
       " '2019-11-19-21-16-58-2D2AAD6513775713',\n",
       " '2019-11-19-21-17-10-9CA1FD3C69E3ABEC',\n",
       " '2019-11-19-21-17-24-A15E803D91077500',\n",
       " '2019-11-19-21-17-30-015B8C8E78EEE6EA',\n",
       " '2019-11-19-21-17-31-80D03B61B9CE8B3A',\n",
       " '2019-11-19-21-17-38-DBC8E0CFE07BA72B',\n",
       " '2019-11-19-21-17-40-DD6C6F87A37B6F69',\n",
       " '2019-11-19-21-18-43-726D85DF82DD42B6',\n",
       " '2019-11-19-21-18-52-64AA5BBF62252BED',\n",
       " '2019-11-19-21-18-58-E277D3AA66D95F33',\n",
       " '2019-11-19-21-19-07-5C4B1E70F731FF90',\n",
       " '2019-11-19-21-19-19-84F1BF5591C662F1',\n",
       " '2019-11-19-21-19-20-4BDAC95AAD02173C',\n",
       " '2019-11-19-21-19-25-71E7786E8955C1B3',\n",
       " '2019-11-19-21-19-33-9E7CF8CDE46F02DC',\n",
       " '2019-11-19-21-19-40-B01ED285D3FDC372',\n",
       " '2019-11-19-21-19-43-F951D6E4D48536E8',\n",
       " '2019-11-19-21-19-51-9946EAFC685C661C',\n",
       " '2019-11-19-21-19-59-B076FAC7FBEE5EE7',\n",
       " '2019-11-19-21-20-12-8784C665F93B85F4',\n",
       " '2019-11-19-21-20-14-2A1E23C6DED55C33',\n",
       " '2019-11-19-21-20-22-621A57476B4540CB',\n",
       " '2019-11-19-21-20-24-081D1E76D4EEDE29',\n",
       " '2019-11-19-21-20-24-9D3B3B52A60698D8',\n",
       " '2019-11-19-21-20-32-30CD6210EA1B192A',\n",
       " '2019-11-19-21-20-49-8BD5F5DEB89602B0',\n",
       " '2019-11-19-21-20-53-648FE4EE1C3E679A',\n",
       " '2019-11-19-21-20-58-E3C9386FC1A16EDB',\n",
       " '2019-11-19-21-21-32-7CEF91F2DA50DD39',\n",
       " '2019-11-19-21-21-36-2C3560310FDB1B0B',\n",
       " '2019-11-19-21-21-45-525121486F870807',\n",
       " '2019-11-19-21-22-15-B3AFF3E08BD14B40',\n",
       " '2019-11-19-21-22-39-75EB1E60B3C2B394',\n",
       " '2019-11-19-21-22-48-55E6C8FD1599A4A5',\n",
       " '2019-11-19-21-22-53-91DB0A9F3DF7B779',\n",
       " '2019-11-19-21-23-03-250A566C7FC1624B',\n",
       " '2019-11-19-21-23-51-916E584D93B010D9',\n",
       " '2019-11-19-21-24-17-C1820F7E03F16EE2',\n",
       " '2019-11-19-21-24-31-706EF2A816195E89',\n",
       " '2019-11-19-21-24-40-7B0363146F625612',\n",
       " '2019-11-19-21-24-47-59D6AFDBBDC430F9',\n",
       " '2019-11-19-21-24-56-F23FE783AD38DBF6',\n",
       " '2019-11-19-21-25-11-B73100A2B80C735F',\n",
       " '2019-11-19-21-25-12-0137A0FF14DE4676',\n",
       " '2019-11-19-21-25-15-35A1FD2FAC1F775D',\n",
       " '2019-11-19-21-25-32-0A0633CE660BEBBD',\n",
       " '2019-11-19-21-26-10-A6E3D1F2657A41C3',\n",
       " '2019-11-19-21-26-25-E5145F728C6FF34C',\n",
       " '2019-11-19-21-26-40-359D9E74B1D1A402',\n",
       " '2019-11-19-21-26-42-9B3C2253945F1501',\n",
       " '2019-11-19-21-26-42-FDFA64E0DCEBDE4E',\n",
       " '2019-11-19-21-26-57-147ACD4A052782A0',\n",
       " '2019-11-19-21-27-03-30C9604244AB36CA',\n",
       " '2019-11-19-21-27-04-B6436FDD5E7DDB3C',\n",
       " '2019-11-19-21-27-26-C73612DE50BA5980',\n",
       " '2019-11-19-21-27-35-B781FA175249169D',\n",
       " '2019-11-19-21-27-43-B0DDB0BF52ADD70A',\n",
       " '2019-11-19-21-27-45-A729FDFCF79CF44C',\n",
       " '2019-11-19-21-28-03-3937F8518B662E36',\n",
       " '2019-11-19-21-28-16-74719BFE34CF1AFD',\n",
       " '2019-11-19-21-28-37-7BDCAB58BB5BCD52',\n",
       " '2019-11-19-21-28-42-7EE83D2CA2F91A8C',\n",
       " '2019-11-19-21-28-56-70D45CC364BB5291',\n",
       " '2019-11-19-21-28-56-F28C3802AA617718',\n",
       " '2019-11-19-21-29-06-309F0E67EFC54416',\n",
       " '2019-11-19-21-29-13-05EFF3A449BE446B',\n",
       " '2019-11-19-21-29-50-51F16DF77FFBF191',\n",
       " '2019-11-19-21-29-56-6938180E395EEF5B',\n",
       " '2019-11-19-21-30-25-0E95AAF60FDE6241',\n",
       " '2019-11-19-21-30-29-51AD0B7E8D671858',\n",
       " '2019-11-19-21-30-40-7B5736975352BCFC',\n",
       " '2019-11-19-21-30-43-5FBAD097F8420BAD',\n",
       " '2019-11-19-21-30-44-5B8CB6F15701C656',\n",
       " '2019-11-19-21-31-07-66BF25349F7860F7',\n",
       " '2019-11-19-21-31-41-555A9B3E932CD92C',\n",
       " '2019-11-19-21-32-18-B81AC7171D6D0BEC',\n",
       " '2019-11-19-21-32-33-0F769601A8C6CC26',\n",
       " '2019-11-19-21-32-40-34DA11C6F2B95F77',\n",
       " '2019-11-19-21-32-42-970F63A482A55032',\n",
       " '2019-11-19-21-32-51-21C3637F8AD23420',\n",
       " '2019-11-19-21-32-53-846F91DAD642FCBB',\n",
       " '2019-11-19-21-33-02-30356274E27A2B34',\n",
       " '2019-11-19-21-33-30-BDDC5613F3096259',\n",
       " '2019-11-19-21-34-18-24825C89A5E28E1A',\n",
       " '2019-11-19-21-34-39-8594F35E897BE258',\n",
       " '2019-11-19-21-35-08-CFD675EB4395244F',\n",
       " '2019-11-19-21-35-09-7761BBFB0C381C15',\n",
       " '2019-11-19-21-35-21-E20610E63A2B58C7',\n",
       " '2019-11-19-21-35-24-F5B9527F0D5FCE52',\n",
       " '2019-11-19-21-35-30-F9BF72C7A6B02BD3',\n",
       " '2019-11-19-21-35-32-0E00BBDFF37EA579',\n",
       " '2019-11-19-21-35-35-261AC6730B9AF55C',\n",
       " '2019-11-19-21-36-03-EE40DE7AAE3954E3',\n",
       " '2019-11-19-21-36-21-50058C3AD2E71796',\n",
       " '2019-11-19-21-36-27-C891B6D32EAFDA96',\n",
       " '2019-11-19-21-36-40-11EA642EB6C408D1',\n",
       " '2019-11-19-21-36-40-7961694051A9E3A2',\n",
       " '2019-11-19-21-36-47-5F8835505AAEE1AB',\n",
       " 'datasets/',\n",
       " 'datasets/df.csv',\n",
       " 'notebooks/',\n",
       " 'notebooks/data_cleanup.ipynb',\n",
       " 'notebooks/vectorization_exploration.ipynb',\n",
       " 'notebooks/yelp_data_initial_exploration.ipynb']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket.get('datasets/df.csv', 'df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/ydc1/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# import final .csv\n",
    "df = pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>['total', 'horrible', 'service', 'crooks', 'ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['adore', 'travis', 'hard', 'rock', 'kelly', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['office', 'organized', 'friendly', 'phillipp'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['went', 'lunch', 'steak', 'sandwich', 'delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>7.0</td>\n",
       "      <td>['today', 'second', 'sessions', 'paid', 'sessi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 stars                                               text  \\\n",
       "0          0     1  Total bill for this horrible service? Over $8G...   \n",
       "1          1     5  I *adore* Travis at the Hard Rock's new Kelly ...   \n",
       "2          2     5  I have to say that this office really has it t...   \n",
       "3          3     5  Went in for a lunch. Steak sandwich was delici...   \n",
       "4          4     1  Today was my second out of three sessions I ha...   \n",
       "\n",
       "                  date  total_votes  \\\n",
       "0  2013-05-07 04:34:36          7.0   \n",
       "1  2017-01-14 21:30:33          0.0   \n",
       "2  2016-11-09 20:09:03          3.0   \n",
       "3  2018-01-09 20:56:38          0.0   \n",
       "4  2018-01-30 23:07:38          7.0   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['total', 'horrible', 'service', 'crooks', 'ac...  \n",
       "1  ['adore', 'travis', 'hard', 'rock', 'kelly', '...  \n",
       "2  ['office', 'organized', 'friendly', 'phillipp'...  \n",
       "3  ['went', 'lunch', 'steak', 'sandwich', 'delici...  \n",
       "4  ['today', 'second', 'sessions', 'paid', 'sessi...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check import\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      object\n",
       "stars           object\n",
       "text            object\n",
       "date            object\n",
       "total_votes    float64\n",
       "tokens          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes of columns in dataframe\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unwanted columns\n",
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>['total', 'horrible', 'service', 'crooks', 'ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['adore', 'travis', 'hard', 'rock', 'kelly', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['office', 'organized', 'friendly', 'phillipp'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['went', 'lunch', 'steak', 'sandwich', 'delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>7.0</td>\n",
       "      <td>['today', 'second', 'sessions', 'paid', 'sessi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stars                                               text  \\\n",
       "0     1  Total bill for this horrible service? Over $8G...   \n",
       "1     5  I *adore* Travis at the Hard Rock's new Kelly ...   \n",
       "2     5  I have to say that this office really has it t...   \n",
       "3     5  Went in for a lunch. Steak sandwich was delici...   \n",
       "4     1  Today was my second out of three sessions I ha...   \n",
       "\n",
       "                  date  total_votes  \\\n",
       "0  2013-05-07 04:34:36          7.0   \n",
       "1  2017-01-14 21:30:33          0.0   \n",
       "2  2016-11-09 20:09:03          3.0   \n",
       "3  2018-01-09 20:56:38          0.0   \n",
       "4  2018-01-30 23:07:38          7.0   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['total', 'horrible', 'service', 'crooks', 'ac...  \n",
       "1  ['adore', 'travis', 'hard', 'rock', 'kelly', '...  \n",
       "2  ['office', 'organized', 'friendly', 'phillipp'...  \n",
       "3  ['went', 'lunch', 'steak', 'sandwich', 'delici...  \n",
       "4  ['today', 'second', 'sessions', 'paid', 'sessi...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars           object\n",
       "text            object\n",
       "date            object\n",
       "total_votes    float64\n",
       "tokens          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mini-dataframe for testing\n",
    "# want to make sure works locally on small dataset before scaling to entire dataset/AWS\n",
    "mini_df = df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new tokenizer\n",
    "def tokenize(document):\n",
    "    doc = nlp(document)\n",
    "    return [token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable to feed into TFIDF Vectorizer fit_transform\n",
    "# to be updated to 'text' column of main dataframe (df['text']) for vectorization in AWS\n",
    "data = mini_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I have to say that this office really has it together, they are so organized and friendly!  Dr. J. Phillipp is a great dentist, very friendly and professional.  The dental assistants that helped in my procedure were amazing, Jewel and Bailey helped me to feel comfortable!  I don't have dental insurance, but they have this insurance through their office you can purchase for $80 something a year and this gave me 25% off all of my dental work, plus they helped me get signed up for care credit which I knew nothing about before this visit!  I highly recommend this office for the nice synergy the whole office has!\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ask</th>\n",
       "      <th>awesome</th>\n",
       "      <th>be</th>\n",
       "      <th>big</th>\n",
       "      <th>clearly</th>\n",
       "      <th>come</th>\n",
       "      <th>dental</th>\n",
       "      <th>dr</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong guest</th>\n",
       "      <th>year</th>\n",
       "      <th>year add</th>\n",
       "      <th>year admit</th>\n",
       "      <th>year ago</th>\n",
       "      <th>year come</th>\n",
       "      <th>year food</th>\n",
       "      <th>year give</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zucchini appetizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.382096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.05084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.199434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.185752</td>\n",
       "      <td>0.092876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.092876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036283</td>\n",
       "      <td>0.023992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.065694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061187</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.061187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061187</td>\n",
       "      <td>0.061187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119463</td>\n",
       "      <td>0.060223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060223</td>\n",
       "      <td>0.060223</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.140649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.034224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.266859</td>\n",
       "      <td>0.248551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248551</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1351 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ask    awesome        be       big    clearly  \\\n",
       "0  0.000000  0.000000  0.000000    0.00000  0.000000  0.000000      0.000   \n",
       "1  0.382096  0.000000  0.000000    0.05084  0.000000  0.000000      0.000   \n",
       "2  0.199434  0.000000  0.000000    0.00000  0.000000  0.000000      0.000   \n",
       "3  0.000000  0.000000  0.000000    0.00000  0.000000  0.000000      0.000   \n",
       "4  0.000000  0.000000  0.000000    0.00000  0.000000  0.000000      0.000   \n",
       "5  0.065694  0.000000  0.061187    0.00000  0.061187  0.000000      0.000   \n",
       "6  0.000000  0.000000  0.000000    0.00000  0.000000  0.000000      0.000   \n",
       "7  0.140649  0.000000  0.000000    0.00000  0.000000  0.000000      0.131   \n",
       "8  0.034224  0.000000  0.000000    0.00000  0.000000  0.000000      0.000   \n",
       "9  0.266859  0.248551  0.000000    0.00000  0.000000  0.248551      0.000   \n",
       "\n",
       "      come    dental        dr  ...  wrong guest      year  year add  \\\n",
       "0  0.00000  0.000000  0.000000  ...     0.000000  0.000000  0.000000   \n",
       "1  0.05084  0.000000  0.000000  ...     0.000000  0.000000  0.000000   \n",
       "2  0.00000  0.185752  0.092876  ...     0.000000  0.061412  0.000000   \n",
       "3  0.00000  0.000000  0.000000  ...     0.000000  0.000000  0.000000   \n",
       "4  0.00000  0.000000  0.000000  ...     0.036283  0.023992  0.000000   \n",
       "5  0.00000  0.000000  0.000000  ...     0.000000  0.000000  0.000000   \n",
       "6  0.00000  0.000000  0.000000  ...     0.000000  0.119463  0.060223   \n",
       "7  0.00000  0.000000  0.000000  ...     0.000000  0.086621  0.000000   \n",
       "8  0.00000  0.000000  0.000000  ...     0.000000  0.000000  0.000000   \n",
       "9  0.00000  0.000000  0.000000  ...     0.000000  0.000000  0.000000   \n",
       "\n",
       "   year admit  year ago  year come  year food  year give  zucchini  \\\n",
       "0    0.000000  0.000000   0.000000      0.000   0.000000  0.000000   \n",
       "1    0.000000  0.000000   0.000000      0.000   0.000000  0.000000   \n",
       "2    0.000000  0.000000   0.000000      0.000   0.092876  0.000000   \n",
       "3    0.000000  0.000000   0.000000      0.000   0.000000  0.000000   \n",
       "4    0.036283  0.000000   0.000000      0.000   0.000000  0.000000   \n",
       "5    0.000000  0.000000   0.000000      0.000   0.000000  0.061187   \n",
       "6    0.000000  0.060223   0.060223      0.000   0.000000  0.000000   \n",
       "7    0.000000  0.000000   0.000000      0.131   0.000000  0.000000   \n",
       "8    0.000000  0.000000   0.000000      0.000   0.000000  0.000000   \n",
       "9    0.000000  0.000000   0.000000      0.000   0.000000  0.000000   \n",
       "\n",
       "   zucchini appetizer  \n",
       "0            0.000000  \n",
       "1            0.000000  \n",
       "2            0.000000  \n",
       "3            0.000000  \n",
       "4            0.000000  \n",
       "5            0.061187  \n",
       "6            0.000000  \n",
       "7            0.000000  \n",
       "8            0.000000  \n",
       "9            0.000000  \n",
       "\n",
       "[10 rows x 1351 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizer\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=0.025, max_df=.95, ngram_range=(1,2))\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "# Learn vocab and transform data into form we want\n",
    "sparse = tfidf.fit_transform(data)\n",
    "\n",
    "# Print word counts\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "dtm = pd.DataFrame(sparse.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "dtm.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_ydc1",
   "language": "python",
   "name": "conda_ydc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
