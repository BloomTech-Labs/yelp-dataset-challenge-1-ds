{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing New csv Load In Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must Pip Install python-decouple each time. \n",
    "#!pip install python-decouple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a Progress Bar Install for the Vectorizer. \n",
    "#import pyprind\n",
    "#import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#import theano\n",
    "import spacy\n",
    "import s3\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everytime you enter\n",
    "bucket = s3.Bucket('yelpchallenge1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/',\n",
       " 'datasets/df.csv',\n",
       " 'notebooks/',\n",
       " 'notebooks/data_cleanup.ipynb',\n",
       " 'notebooks/vectorization_exploration.ipynb',\n",
       " 'notebooks/yelp_data_initial_exploration.ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look inside the bucket.\n",
    "bucket.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only have to run this once.\n",
    "# Installs the .csv 'Locally' on SageMaker Instance\n",
    "\n",
    "#bucket.get('datasets/df.csv', 'df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/ydc1/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read df.csv\n",
    "# Time to Load In: 8 Minutes.... \n",
    "df = pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>['total', 'horrible', 'service', 'crooks', 'ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['adore', 'travis', 'hard', 'rock', 'kelly', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['office', 'organized', 'friendly', 'phillipp'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['went', 'lunch', 'steak', 'sandwich', 'delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>7.0</td>\n",
       "      <td>['today', 'second', 'sessions', 'paid', 'sessi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 stars                                               text  \\\n",
       "0          0     1  Total bill for this horrible service? Over $8G...   \n",
       "1          1     5  I *adore* Travis at the Hard Rock's new Kelly ...   \n",
       "2          2     5  I have to say that this office really has it t...   \n",
       "3          3     5  Went in for a lunch. Steak sandwich was delici...   \n",
       "4          4     1  Today was my second out of three sessions I ha...   \n",
       "\n",
       "                  date  total_votes  \\\n",
       "0  2013-05-07 04:34:36          7.0   \n",
       "1  2017-01-14 21:30:33          0.0   \n",
       "2  2016-11-09 20:09:03          3.0   \n",
       "3  2018-01-09 20:56:38          0.0   \n",
       "4  2018-01-30 23:07:38          7.0   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['total', 'horrible', 'service', 'crooks', 'ac...  \n",
       "1  ['adore', 'travis', 'hard', 'rock', 'kelly', '...  \n",
       "2  ['office', 'organized', 'friendly', 'phillipp'...  \n",
       "3  ['went', 'lunch', 'steak', 'sandwich', 'delici...  \n",
       "4  ['today', 'second', 'sessions', 'paid', 'sessi...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check import\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      object\n",
       "stars           object\n",
       "text            object\n",
       "date            object\n",
       "total_votes    float64\n",
       "tokens          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes of columns in dataframe\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unwanted columns\n",
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>['total', 'horrible', 'service', 'crooks', 'ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['adore', 'travis', 'hard', 'rock', 'kelly', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['office', 'organized', 'friendly', 'phillipp'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['went', 'lunch', 'steak', 'sandwich', 'delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>7.0</td>\n",
       "      <td>['today', 'second', 'sessions', 'paid', 'sessi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stars                                               text  \\\n",
       "0     1  Total bill for this horrible service? Over $8G...   \n",
       "1     5  I *adore* Travis at the Hard Rock's new Kelly ...   \n",
       "2     5  I have to say that this office really has it t...   \n",
       "3     5  Went in for a lunch. Steak sandwich was delici...   \n",
       "4     1  Today was my second out of three sessions I ha...   \n",
       "\n",
       "                  date  total_votes  \\\n",
       "0  2013-05-07 04:34:36          7.0   \n",
       "1  2017-01-14 21:30:33          0.0   \n",
       "2  2016-11-09 20:09:03          3.0   \n",
       "3  2018-01-09 20:56:38          0.0   \n",
       "4  2018-01-30 23:07:38          7.0   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['total', 'horrible', 'service', 'crooks', 'ac...  \n",
       "1  ['adore', 'travis', 'hard', 'rock', 'kelly', '...  \n",
       "2  ['office', 'organized', 'friendly', 'phillipp'...  \n",
       "3  ['went', 'lunch', 'steak', 'sandwich', 'delici...  \n",
       "4  ['today', 'second', 'sessions', 'paid', 'sessi...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars           object\n",
       "text            object\n",
       "date            object\n",
       "total_votes    float64\n",
       "tokens          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6876898, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mini-dataframe for testing\n",
    "# want to make sure works locally on small dataset before scaling to entire dataset/AWS\n",
    "#mini_df = df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new tokenizer\n",
    "def tokenize(document):\n",
    "    doc = nlp(document)\n",
    "    return [token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable to feed into TFIDF Vectorizer fit_transform\n",
    "# to be updated to 'text' column of main dataframe (df['text']) for vectorization in AWS\n",
    "data = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Total bill for this horrible service? Over $8G...\n",
       "1    I *adore* Travis at the Hard Rock's new Kelly ...\n",
       "2    I have to say that this office really has it t...\n",
       "3    Went in for a lunch. Steak sandwich was delici...\n",
       "4    Today was my second out of three sessions I ha...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6876898,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131090"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values/ Before Drop.nas\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping na from Data\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BEGONE NON-EXISTENT DATA\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6745808,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I have to say that this office really has it together, they are so organized and friendly!  Dr. J. Phillipp is a great dentist, very friendly and professional.  The dental assistants that helped in my procedure were amazing, Jewel and Bailey helped me to feel comfortable!  I don't have dental insurance, but they have this insurance through their office you can purchase for $80 something a year and this gave me 25% off all of my dental work, plus they helped me get signed up for care credit which I knew nothing about before this visit!  I highly recommend this office for the nice synergy the whole office has!\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=0.025, max_df=.95, ngram_range=(1,2))\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "# Learn vocab and transform data into form we want\n",
    "\n",
    "#sparse = tfidf.fit_transform(data)\n",
    "\n",
    "# Print word counts\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "\n",
    "#dtm = pd.DataFrame(sparse.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "\n",
    "#dtm.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6745808,)\n",
      "3503987    The Inn is wonderful! I've been in every room ...\n",
      "3503988    extremely unhygenic toilets both mens and wome...\n",
      "3503989    We are avid happy hour folks and we absolutely...\n",
      "3503990    Atlas changed out our kitchen sink and fixture...\n",
      "3503991    This is one of the only restaurants in this ar...\n",
      "3503992    Absolutely love this place! Showed them a pic ...\n",
      "3503993    I can't go five stars because while they win y...\n",
      "3503994    Horrible Service!  I make an appointment for a...\n",
      "3503995    I watched the movie the Founder on Netflix and...\n",
      "3503996    Fostering department is very incompetent, rude...\n",
      "3503997    Picked up 2 pizzas absolutely no cheese pure s...\n",
      "3503998    This place is awesome!!!! Dropped in for a hap...\n",
      "3503999    i'm not going to lie and pretend i was sober a...\n",
      "3504000    I LOVE LOVE LOVE VEGENATION! Literally have tr...\n",
      "3504001    I have finally found an auto repair shop that ...\n",
      "3504002    Why is it that the girls that work the juice b...\n",
      "3504003    Usually a great dinner experience... lunch tod...\n",
      "3504004    We just had a tech come by to fix some electri...\n",
      "3504005    Fantastic experience with Pat! He gave us a th...\n",
      "3504006    I am very picky when it comes to my Asian cuis...\n",
      "3504007    A visit to the dentist can be dreadful...lucki...\n",
      "3504008    Upon first entry the shop is your standard, cu...\n",
      "3504009    I had called an early carry-out order in while...\n",
      "3504010    I love this place! The best sake bombs you'll ...\n",
      "3504011    The premise of dim sum bar really got me curio...\n",
      "3504012    Just got my first haircut here! It's a very sm...\n",
      "3504013    I honestly have not walked into a more warm, i...\n",
      "3504014    My fiancé and I lived here just shy of a year....\n",
      "3504015    Usually the place in ok but this morning I pla...\n",
      "3504016    First time at Mama Ricotta's....came here on a...\n",
      "                                 ...                        \n",
      "6876868    4.5 - 5 STARS.Tiny place, hidden away in the b...\n",
      "6876869    I brought my daughter's Toyota Sienna there to...\n",
      "6876870    I needed an older sectional cleaned and yelp s...\n",
      "6876871    Created my own tuna and salmon custom poke bow...\n",
      "6876872    Our lunch with our close freind was excellent....\n",
      "6876873    This is my second patio that I have used Beat ...\n",
      "6876874    I think this is a place for people who don't u...\n",
      "6876875    I have tried many nail spas in Indian Trail bu...\n",
      "6876876    The food is great ... we have had it 3 days in...\n",
      "6876877    This STORE IS Price gouging!! Do not go here f...\n",
      "6876878    Went here on Canada day. This place was super ...\n",
      "6876879    This place was so convenient, fast, and not at...\n",
      "6876880    Kenny's here!! First off the owner of this pla...\n",
      "6876881    Let our story be a cautionary tale so you can ...\n",
      "6876882    So happy a great coffee joint opened in the we...\n",
      "6876883    Went to have my thyroid checked up - they said...\n",
      "6876884    I have been wanting to try this place and it d...\n",
      "6876885    Cuteology Cakes created a cake for my Father o...\n",
      "6876886    Great food aside, I really want to make a shou...\n",
      "6876887    Parking is ok now that baseball is over. But t...\n",
      "6876888    The service is quick, the food is very good, a...\n",
      "6876889    Great for a quick stop for a pre-made slice of...\n",
      "6876890    As soon as we got there we got amazing service...\n",
      "6876891    We've been here b4 with no major problems but ...\n",
      "6876892    Best sushi place I've ever tasted...My favorit...\n",
      "6876893    I have been coming here for years and this pla...\n",
      "6876894    I think this owner and the owner of Amy's Baki...\n",
      "6876895    Off the grid Mexican in Vegas. Very tasty, qua...\n",
      "6876896    We hired Taco Naco to cater our family party a...\n",
      "6876897    Having just come back from Hawaii a few months...\n",
      "Name: text, Length: 3372903, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Attempting to Break Up Data\n",
    "    # Breaking up data column into TWO Columns. \n",
    "        # data_1 & data_2 \n",
    "        # data_1 will have 3,372,904 rows. \n",
    "        # data_2 will have 3,372,905 rows. \n",
    "#\n",
    "print(data.shape)\n",
    "data_1 = data[:3372904]\n",
    "data_2 = data[3372905:]\n",
    "print(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vocabulary and get word counts per document\n",
    "# Learn vocab and transform data into form we want\n",
    "\n",
    "    # Started at 7:09 PM / 11-24-19\n",
    "    # data_1 has 3,372,904 rows\n",
    "\n",
    "sparse = tfidf.fit_transform(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vocabulary and get word counts per document\n",
    "# Learn vocab and transform data into form we want\n",
    "\n",
    "    # Started at 00:00 PM / 11-24-19\n",
    "    # data_2 has 3,372,904 rows\n",
    "\n",
    "sparse_1 = tfidf.fit_transform(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a Progress Bar Install for the Vectorizer.\n",
    "# Works pretty quickly..\n",
    "# Given that nothing is running.. HA! \n",
    "# Also a pointless feature that I spent 20 minutes on. . . \n",
    "\n",
    "#import pyprind\n",
    "#import psutil\n",
    "#import random\n",
    "#import time\n",
    "\n",
    "#n = 100\n",
    "#bar = pyprind.ProgBar(n, monitor=True)\n",
    "#for i in range(n):\n",
    "    #time.sleep(0.05)\n",
    "#tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=0.025, max_df=.95, ngram_range=(1,2))\n",
    "    #bar.update()\n",
    "#print(bar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_ydc1",
   "language": "python",
   "name": "conda_ydc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
