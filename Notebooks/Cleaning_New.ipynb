{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Up: \n",
    "Before Running the cell below, you must ensure that these have been run in Terminal **IN ORDER** : \n",
    "- conda update -n base -c defaults conda \n",
    "\n",
    "    - cd SageMaker\n",
    "    \n",
    "      - cd yelp-dataset-challenge-1-ds\n",
    "      \n",
    "         - conda env create -f environment.yml\n",
    "          \n",
    "            - source activate ydc1 \n",
    "                \n",
    "                - pip install python-decouple\n",
    "                  \n",
    "                  - pip install pprintpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['API/',\n",
       " 'API/api.py',\n",
       " 'API/api_exploration.ipynb',\n",
       " 'Environments/',\n",
       " 'Environments/environment.yml',\n",
       " 'Flask_App/',\n",
       " 'Flask_App/Pipfile',\n",
       " 'Flask_App/__init__.py',\n",
       " 'Flask_App/app.py',\n",
       " 'Flask_App/models.py',\n",
       " 'Flask_App/yelp.py',\n",
       " 'Model/',\n",
       " 'Model/vect_1.sav',\n",
       " 'datasets/',\n",
       " 'datasets/df.csv',\n",
       " 'datasets/dtm.csv',\n",
       " 'datasets/dtm_final.csv',\n",
       " 'notebooks/',\n",
       " 'notebooks/data_cleanup.ipynb',\n",
       " 'notebooks/official_NB.ipynb',\n",
       " 'notebooks/vectorization_exploration.ipynb',\n",
       " 'notebooks/yelp_data_initial_exploration.ipynb']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import s3\n",
    "from pprintpp import pprint as pp\n",
    "from sklearn.externals import joblib\n",
    "import json\n",
    "\n",
    "# Load in Bucket\n",
    "bucket = s3.Bucket('yelpchallenge1')\n",
    "\n",
    "# Look inside Bucket \n",
    "bucket.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    ### ***** DO NOT RUN. ******* #### \n",
    "                  ### ***** ALREADY INSTALLED. ****** ###\n",
    "\n",
    "    # Installs the File 'Locally' on SageMaker Instance / Only have to run these once: \n",
    "\n",
    "bucket.get('datasets/df.csv', 'df.csv')\n",
    "\n",
    "    # Installing .json Files 'Locally'\n",
    "    \n",
    "bucket.get('datasets/user.json', 'user.json')\n",
    "bucket.get('datasets/review.json', 'review.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data: Complete as of ***8:14 PM : 12/19/2019***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning df.csv & saving Cleaned df.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    ### ***** DO NOT RUN. ******* #### \n",
    "                  ### ***** ALREADY COMPLETE. ****** ###\n",
    "# Further Cleaning of df.csv: \n",
    "# Import \n",
    "df = pd.read_csv('df.csv')\n",
    "# Dropping Columns:\n",
    "df = df.drop(columns=['Unnamed: 0', 'stars'])\n",
    "\n",
    "# Dropping all Missing / Na Values from Entire Dataframe:\n",
    "df = df.dropna()\n",
    "\n",
    "    # Saving Cleaned df.csv \n",
    "df.to_csv(index=True)\n",
    "df.to_csv(r'df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting user_json & to Pandas DataFrame / Saving as user.csv & review.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "                              # ******* DO NOT RUN! ******* # \n",
    "                            # ***** ALREADY COMPLETE. ****** # \n",
    " # import user.json\n",
    "with open('user.json') as f:\n",
    "    user = json.loads(\"[\" + \n",
    "                      f.read().replace(\"}\\n{\", \"},\\n{\") + \n",
    "                      \"]\")\n",
    "    \n",
    "    # convert user.json files to pandas DataFrame 'user_df'\n",
    "user_df = pd.DataFrame(user)\n",
    "\n",
    "    # Saving user_df as csv file. \n",
    "user_df.to_csv(index=True)\n",
    "user_df.to_csv(r'user.csv')\n",
    "\n",
    "# Import review.json \n",
    "with open('review.json') as f:\n",
    "    review = json.loads(\"[\" + \n",
    "                        f.read().replace(\"}\\n{\", \"},\\n{\") + \n",
    "                        \"]\")\n",
    "    \n",
    "    # convert review.json files to pandas DataFrame 'review_df'\n",
    "review_df = pd.DataFrame(review)\n",
    "\n",
    "    # Saving user_df as csv file. \n",
    "review_df.to_csv(index=True)\n",
    "review_df.to_csv(r'review.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merging: Complete as of ***8:14 PM : 12/19/2019***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # ***** New DTM DF HAS BEEN CREATED. DO NOT RUN THIS CELL **** #\n",
    "# Read-in dtm.csv (Original)\n",
    "dtm = pd.read_csv('dtm.csv')\n",
    "\n",
    "    # Taking Stars Column\n",
    "stars = df['stars']\n",
    "\n",
    "    # Adding stars column to dtm\n",
    "dtm['stars']=df['stars']\n",
    "\n",
    "# Shifting 'Stars' Column to front of Df,\n",
    "cols = list(dtm.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "dtm = dtm[cols]\n",
    "\n",
    "    # Dropping \"-PRON-\", 'year -PRON-', and ' ' Columns\n",
    "dtm = dtm.drop(columns=[' ', '  -PRON-', 'year -PRON-'])#Cut 135,000 Rows of df['stars'] Column to fix Memory Error. \n",
    "    # Label as \"stars\"\n",
    "stars = df.stars[0:135000]\n",
    "stars.shape\n",
    "    # Adding stars to dtm2\n",
    "dtm2['stars']=df['stars'][0:135000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "             # ***** New DTM2 DF HAS BEEN CREATED. DO NOT RUN THIS CELL **** #\n",
    "    \n",
    "    # Read-in dtm2.csv(Old)\n",
    "dtm2 = pd.read_csv('dtm2.csv')\n",
    "\n",
    "    # Taking Stars Column\n",
    "stars = df['stars']\n",
    "\n",
    "    # Adding stars column to dtm\n",
    "dtm2['stars']=df['stars']\n",
    "\n",
    "    # Shifting 'Stars' Column to front of Df,\n",
    "cols = list(dtm2.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "dtm2 = dtm2[cols]\n",
    "\n",
    "dtm2 = dtm2.drop(columns=['stars'])\n",
    "\n",
    "    # Dropping columns: \n",
    "dtm2 = dtm2.drop(columns=[' ' , '  '])\n",
    "dtm2 = dtm2.drop(columns=['  -PRON-','  i',  '  the',  '  this', '$', \"'s\"])\n",
    "    # Saving dtm2.csv \n",
    "dtm2.to_csv(index=True)\n",
    "dtm2.to_csv(r'dtm2.csv')\n",
    "\n",
    "    # Cut 135,000 Rows of df['stars'] Column to fix Memory Error. \n",
    "        # Label as \"stars\"     \n",
    "stars = df.stars[0:135000]\n",
    "stars.shape\n",
    "\n",
    "        # Adding stars to dtm2\n",
    "dtm2['stars']=df['stars'][0:135000]\n",
    "\n",
    "    # Saving Final df as 'dtm_final'\n",
    "dtm_final = dtm2\n",
    "\n",
    "    # Saving dtm_final.csv \n",
    "dtm_final.to_csv(index=True)\n",
    "dtm_final.to_csv(r'dtm_final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-in dtm_final.csv (FINAL)\n",
    "#dtm_final = pd.read_csv('dtm_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean / Analyze user.csv: Complete as of ***10:14 PM 12/19/2019***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/ydc1/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/ec2-user/anaconda3/envs/ydc1/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "    # Read-in user.csv\n",
    "user = pd.read_csv('user.csv')\n",
    "    # Read-in review.csv\n",
    "review = pd.read_csv('review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_stars         0\n",
      "compliment_cool       0\n",
      "compliment_cute       0\n",
      "compliment_funny      0\n",
      "compliment_hot        0\n",
      "compliment_list       0\n",
      "compliment_more       0\n",
      "compliment_note       0\n",
      "compliment_photos     0\n",
      "compliment_plain      0\n",
      "compliment_profile    0\n",
      "compliment_writer     0\n",
      "cool                  0\n",
      "fans                  0\n",
      "friends               0\n",
      "funny                 0\n",
      "name                  0\n",
      "review_count          0\n",
      "useful                0\n",
      "user_id               0\n",
      "yelping_since         0\n",
      "dtype: int64\n",
      "(1637135, 21)\n"
     ]
    }
   ],
   "source": [
    "# Check Read-in of df_user\n",
    "# Checking Null Values and Shape\n",
    "pp(user.isna().sum())\n",
    "pp(user.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three Problems: \n",
    "**Problem 1:**\n",
    "user['Unamed: 0'] should not exist. \n",
    "\n",
    "**Problem 2:**\n",
    "user['elite'] has 1,565,761 Missing Values. \n",
    "\n",
    "**Problem 3:** \n",
    "user['name'] has 3 Missing Values. \n",
    "\n",
    "**Solution?:**\n",
    "Drop user['Unamed: 0' , 'elite']  Columns.\n",
    "\n",
    "Drop Missing Values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution:\n",
    "user = user.drop(columns=['Unnamed: 0', 'elite' ])\n",
    "user = user.dropna()\n",
    "# Save Cleaned user_df.csv \n",
    "user.to_csv(index=True)\n",
    "user.to_csv(r'user.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['average_stars', 'compliment_cool', 'compliment_cute',\n",
       "       'compliment_funny', 'compliment_hot', 'compliment_list',\n",
       "       'compliment_more', 'compliment_note', 'compliment_photos',\n",
       "       'compliment_plain', 'compliment_profile', 'compliment_writer', 'cool',\n",
       "       'fans', 'friends', 'funny', 'name', 'review_count', 'useful', 'user_id',\n",
       "       'yelping_since'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unused columns from user_df\n",
    "user = user.drop(columns=['average_stars', 'compliment_cool', 'compliment_cute',\n",
    "       'compliment_funny', 'compliment_hot', 'compliment_list',\n",
    "       'compliment_more', 'compliment_note', 'compliment_photos',\n",
    "       'compliment_plain', 'compliment_profile', 'compliment_writer', 'cool', 'friends', 'funny', 'useful'])\n",
    "\n",
    "# Save Cleaned user_df.csv \n",
    "user.to_csv(index=True)\n",
    "user.to_csv(r'user.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean / Analyze review.csv: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cool         0\n",
      "date         2\n",
      "funny        2\n",
      "review_id    2\n",
      "text         4\n",
      "useful       4\n",
      "user_id      4\n",
      "dtype: int64\n",
      "(6685902, 7)\n"
     ]
    }
   ],
   "source": [
    "# Check Read-in of review.csv\n",
    "# Checking Null Values and Shape\n",
    "pp(review.isna().sum())\n",
    "pp(review.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minor Problem(s) with a Simple Solution**\n",
    "\n",
    "**Problems?:** \n",
    "review['date', 'funny', 'review_id', 'stars', 'text', 'useful'] Columns have NaN's. \n",
    "\n",
    "review['Unnamed: 0'] Not Supposed to be there.\n",
    "\n",
    "**Solution?:**\n",
    "Drop Missing Values from review DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-7f07be04a0de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#review = review.drop(columns=['Unnamed: 0', 'stars', 'business_id'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Save Cleaned review_df.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'review.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ydc1/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3022\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3023\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Solution: \n",
    "review = review.dropna()\n",
    "#review = review.drop(columns=['Unnamed: 0', 'stars', 'business_id'])\n",
    "# Save Cleaned review_df.csv \n",
    "review.to_csv(index=True)\n",
    "review.to_csv(r'review.csv')b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>funny</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cool  funny  useful                 user_id\n",
       "0     0    1.0     6.0  hG7b0MtEbXx5QzbzE6C_VA"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining review.csv, & df.csv \n",
    "\n",
    "**Description**: \n",
    "\n",
    "Combining based on their *Unique Account ID's.*\n",
    "The end Product will be One DataFrame Consisting of Each Account:\n",
    "- **Name**, \n",
    "- **User_ID**,\n",
    "- **Review_ID**,\n",
    "- **Text**,\n",
    "- **That Users respective review(s)**,\n",
    "- **Interactions that Review (i.e: Cool, Funny, Useful)**  \n",
    "\n",
    "The goal of the model is to have the ability to type in the Review you are wanting to post on Yelp, and give the User the ability to Predict What type of Interaction they would potentially receive and Total Number of each interaction. The model Accuracy will be Displayed beside the Prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>['total', 'horrible', 'service', 'crooks', 'ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['adore', 'travis', 'hard', 'rock', 'kelly', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['office', 'organized', 'friendly', 'phillipp'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['went', 'lunch', 'steak', 'sandwich', 'delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>7.0</td>\n",
       "      <td>['today', 'second', 'sessions', 'paid', 'sessi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                 date  \\\n",
       "0  Total bill for this horrible service? Over $8G...  2013-05-07 04:34:36   \n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...  2017-01-14 21:30:33   \n",
       "2  I have to say that this office really has it t...  2016-11-09 20:09:03   \n",
       "3  Went in for a lunch. Steak sandwich was delici...  2018-01-09 20:56:38   \n",
       "4  Today was my second out of three sessions I ha...  2018-01-30 23:07:38   \n",
       "\n",
       "   total_votes                                             tokens  \n",
       "0          7.0  ['total', 'horrible', 'service', 'crooks', 'ac...  \n",
       "1          0.0  ['adore', 'travis', 'hard', 'rock', 'kelly', '...  \n",
       "2          3.0  ['office', 'organized', 'friendly', 'phillipp'...  \n",
       "3          0.0  ['went', 'lunch', 'steak', 'sandwich', 'delici...  \n",
       "4          7.0  ['today', 'second', 'sessions', 'paid', 'sessi...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>funny</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ssoyf2_x0EQMed6fgHeMyQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cool  funny  useful                 user_id\n",
       "0     0    1.0     6.0  hG7b0MtEbXx5QzbzE6C_VA\n",
       "1     0    0.0     0.0  yXQM5uF2jS6es16SJzNHfg\n",
       "2     0    0.0     3.0  n6-Gk65cPZL6Uz8qRm3NYw\n",
       "3     0    0.0     0.0  dacAIZ6fTM6mqwW5uxkskg\n",
       "4     0    0.0     7.0  ssoyf2_x0EQMed6fgHeMyQ"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_ydc1",
   "language": "python",
   "name": "conda_ydc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
