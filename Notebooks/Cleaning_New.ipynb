{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Up: \n",
    "Before Running the cell below, you must ensure that these have been run in Terminal **IN ORDER** : \n",
    "- conda update -n base -c defaults conda \n",
    "\n",
    "    - cd SageMaker\n",
    "    \n",
    "      - cd yelp-dataset-challenge-1-ds\n",
    "      \n",
    "         - conda env create -f environment.yml\n",
    "          \n",
    "            - source activate ydc1 \n",
    "                \n",
    "                - pip install python-decouple\n",
    "                  \n",
    "                  - pip install pprintpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['API/',\n",
       " 'API/api.py',\n",
       " 'API/api_exploration.ipynb',\n",
       " 'Environments/',\n",
       " 'Environments/environment.yml',\n",
       " 'Flask_App/',\n",
       " 'Flask_App/Pipfile',\n",
       " 'Flask_App/__init__.py',\n",
       " 'Flask_App/app.py',\n",
       " 'Flask_App/models.py',\n",
       " 'Flask_App/yelp.py',\n",
       " 'Model/',\n",
       " 'Model/vect_1.sav',\n",
       " 'datasets/',\n",
       " 'datasets/df.csv',\n",
       " 'datasets/dtm.csv',\n",
       " 'datasets/dtm_final.csv',\n",
       " 'notebooks/',\n",
       " 'notebooks/data_cleanup.ipynb',\n",
       " 'notebooks/official_NB.ipynb',\n",
       " 'notebooks/vectorization_exploration.ipynb',\n",
       " 'notebooks/yelp_data_initial_exploration.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import s3\n",
    "from pprintpp import pprint as pp\n",
    "from sklearn.externals import joblib\n",
    "import json\n",
    "\n",
    "# Load in Bucket\n",
    "bucket = s3.Bucket('yelpchallenge1')\n",
    "\n",
    "# Look inside Bucket \n",
    "bucket.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    ### ***** DO NOT RUN. ******* #### \n",
    "                  ### ***** ALREADY INSTALLED. ****** ###\n",
    "\n",
    "    # Installs the File 'Locally' on SageMaker Instance / Only have to run these once: \n",
    "\n",
    "bucket.get('datasets/df.csv', 'df.csv')\n",
    "\n",
    "    # Installing .json Files 'Locally'\n",
    "    \n",
    "bucket.get('datasets/user.json', 'user.json')\n",
    "bucket.get('datasets/review.json', 'review.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data: Complete as of ***8:14 PM : 12/19/2019***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning df.csv & saving Cleaned df.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    ### ***** DO NOT RUN. ******* #### \n",
    "                  ### ***** ALREADY COMPLETE. ****** ###\n",
    "# Further Cleaning of df.csv: \n",
    "# Import \n",
    "df = pd.read_csv('df.csv')\n",
    "# Dropping Columns:\n",
    "#df = df.drop(columns=['Unnamed: 0', 'stars'])\n",
    "\n",
    "# Dropping all Missing / Na Values from Entire Dataframe:\n",
    "df = df.dropna()\n",
    "\n",
    "    # Saving Cleaned df.csv \n",
    "df.to_csv(index=True)\n",
    "df.to_csv(r'df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting user_json & to Pandas DataFrame / Saving as user.csv & review.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "                              # ******* DO NOT RUN! ******* # \n",
    "                            # ***** ALREADY COMPLETE. ****** # \n",
    " # import user.json\n",
    "with open('user.json') as f:\n",
    "    user = json.loads(\"[\" + \n",
    "                      f.read().replace(\"}\\n{\", \"},\\n{\") + \n",
    "                      \"]\")\n",
    "    \n",
    "    # convert user.json files to pandas DataFrame 'user_df'\n",
    "user_df = pd.DataFrame(user)\n",
    "\n",
    "    # Saving user_df as csv file. \n",
    "user_df.to_csv(index=True)\n",
    "user_df.to_csv(r'user.csv')\n",
    "\n",
    "# Import review.json \n",
    "with open('review.json') as f:\n",
    "    review = json.loads(\"[\" + \n",
    "                        f.read().replace(\"}\\n{\", \"},\\n{\") + \n",
    "                        \"]\")\n",
    "    \n",
    "    # convert review.json files to pandas DataFrame 'review_df'\n",
    "review_df = pd.DataFrame(review)\n",
    "\n",
    "    # Saving user_df as csv file. \n",
    "review_df.to_csv(index=True)\n",
    "review_df.to_csv(r'review.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merging: Complete as of ***8:14 PM : 12/19/2019***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # ***** New DTM DF HAS BEEN CREATED. DO NOT RUN THIS CELL **** #\n",
    "# Read-in dtm.csv (Original)\n",
    "dtm = pd.read_csv('dtm.csv')\n",
    "\n",
    "    # Taking Stars Column\n",
    "stars = df['stars']\n",
    "\n",
    "    # Adding stars column to dtm\n",
    "dtm['stars']=df['stars']\n",
    "\n",
    "# Shifting 'Stars' Column to front of Df,\n",
    "cols = list(dtm.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "dtm = dtm[cols]\n",
    "\n",
    "    # Dropping \"-PRON-\", 'year -PRON-', and ' ' Columns\n",
    "dtm = dtm.drop(columns=[' ', '  -PRON-', 'year -PRON-'])#Cut 135,000 Rows of df['stars'] Column to fix Memory Error. \n",
    "    # Label as \"stars\"\n",
    "stars = df.stars[0:135000]\n",
    "stars.shape\n",
    "    # Adding stars to dtm2\n",
    "dtm2['stars']=df['stars'][0:135000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "             # ***** New DTM2 DF HAS BEEN CREATED. DO NOT RUN THIS CELL **** #\n",
    "    \n",
    "    # Read-in dtm2.csv(Old)\n",
    "dtm2 = pd.read_csv('dtm2.csv')\n",
    "\n",
    "    # Taking Stars Column\n",
    "stars = df['stars']\n",
    "\n",
    "    # Adding stars column to dtm\n",
    "dtm2['stars']=df['stars']\n",
    "\n",
    "    # Shifting 'Stars' Column to front of Df,\n",
    "cols = list(dtm2.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "dtm2 = dtm2[cols]\n",
    "\n",
    "dtm2 = dtm2.drop(columns=['stars'])\n",
    "\n",
    "    # Dropping columns: \n",
    "dtm2 = dtm2.drop(columns=[' ' , '  '])\n",
    "dtm2 = dtm2.drop(columns=['  -PRON-','  i',  '  the',  '  this', '$', \"'s\"])\n",
    "    # Saving dtm2.csv \n",
    "dtm2.to_csv(index=True)\n",
    "dtm2.to_csv(r'dtm2.csv')\n",
    "\n",
    "    # Cut 135,000 Rows of df['stars'] Column to fix Memory Error. \n",
    "        # Label as \"stars\"     \n",
    "stars = df.stars[0:135000]\n",
    "stars.shape\n",
    "\n",
    "        # Adding stars to dtm2\n",
    "dtm2['stars']=df['stars'][0:135000]\n",
    "\n",
    "    # Saving Final df as 'dtm_final'\n",
    "dtm_final = dtm2\n",
    "\n",
    "    # Saving dtm_final.csv \n",
    "dtm_final.to_csv(index=True)\n",
    "dtm_final.to_csv(r'dtm_final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-in dtm_final.csv (FINAL)\n",
    "#dtm_final = pd.read_csv('dtm_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean / Analyze user.csv: Complete as of ***10:14 PM 12/19/2019***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/ydc1/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "    # Read-in user.csv\n",
    "user = pd.read_csv('user.csv')\n",
    "    # Read-in review.csv\n",
    "review = pd.read_csv('review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0       0\n",
      "fans             0\n",
      "name             0\n",
      "review_count     0\n",
      "user_id          0\n",
      "yelping_since    0\n",
      "dtype: int64\n",
      "(1637135, 6)\n"
     ]
    }
   ],
   "source": [
    "# Check Read-in of df_user\n",
    "# Checking Null Values and Shape\n",
    "pp(user.isna().sum())\n",
    "pp(user.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three Problems: \n",
    "**Problem 1:**\n",
    "user['Unamed: 0'] should not exist. \n",
    "\n",
    "**Problem 2:**\n",
    "user['elite'] has 1,565,761 Missing Values. \n",
    "\n",
    "**Problem 3:** \n",
    "user['name'] has 3 Missing Values. \n",
    "\n",
    "**Solution?:**\n",
    "Drop user['Unamed: 0' , 'elite']  Columns.\n",
    "\n",
    "Drop Missing Values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution:\n",
    "user = user.drop(columns=['Unnamed: 0', 'elite' ])\n",
    "user = user.dropna()\n",
    "# Save Cleaned user_df.csv \n",
    "user.to_csv(index=True)\n",
    "user.to_csv(r'user.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['average_stars', 'compliment_cool', 'compliment_cute',\n",
       "       'compliment_funny', 'compliment_hot', 'compliment_list',\n",
       "       'compliment_more', 'compliment_note', 'compliment_photos',\n",
       "       'compliment_plain', 'compliment_profile', 'compliment_writer', 'cool',\n",
       "       'fans', 'friends', 'funny', 'name', 'review_count', 'useful', 'user_id',\n",
       "       'yelping_since'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unused columns from user_df\n",
    "user = user.drop(columns=['average_stars', 'compliment_cool', 'compliment_cute',\n",
    "       'compliment_funny', 'compliment_hot', 'compliment_list',\n",
    "       'compliment_more', 'compliment_note', 'compliment_photos',\n",
    "       'compliment_plain', 'compliment_profile', 'compliment_writer', 'cool', 'friends', 'funny', 'useful'])\n",
    "\n",
    "# Save Cleaned user_df.csv \n",
    "user.to_csv(index=True)\n",
    "user.to_csv(r'user.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean / Analyze review.csv: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0     0\n",
      "business_id    0\n",
      "cool           0\n",
      "date           2\n",
      "funny          2\n",
      "review_id      2\n",
      "stars          2\n",
      "text           4\n",
      "useful         4\n",
      "user_id        4\n",
      "dtype: int64\n",
      "(6685902, 10)\n"
     ]
    }
   ],
   "source": [
    "# Check Read-in of review.csv\n",
    "# Checking Null Values and Shape\n",
    "pp(review.isna().sum())\n",
    "pp(review.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minor Problem(s) with a Simple Solution**\n",
    "\n",
    "**Problems?:** \n",
    "review['date', 'funny', 'review_id', 'stars', 'text', 'useful'] Columns have NaN's. \n",
    "\n",
    "review['Unnamed: 0'] Not Supposed to be there.\n",
    "\n",
    "**Solution?:**\n",
    "Drop Missing Values from review DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: \n",
    "review = review.dropna()\n",
    "review = review.drop(columns=['Unnamed: 0', 'stars', 'business_id'])\n",
    "# Save Cleaned review_df.csv \n",
    "review.to_csv(index=True)\n",
    "review.to_csv(r'review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = review.drop(columns=['text'])\n",
    "review.to_csv(index=True)\n",
    "review.to_csv(r'review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding df['text', 'tokens'] to review.csv\n",
    "review['text'] = df['text']\n",
    "review['tokens'] = df['tokens']\n",
    "#review = review.drop(columns=['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>6.0</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>3.0</td>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11a8sVPMUFtaC7_ABRkmtw</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ssoyf2_x0EQMed6fgHeMyQ</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cool                 date  funny               review_id  useful  \\\n",
       "0    0  2013-05-07 04:34:36    1.0  Q1sbwvVQXV2734tPgoKj4Q     6.0   \n",
       "1    0  2017-01-14 21:30:33    0.0  GJXCdrto3ASJOqKeVWPi6Q     0.0   \n",
       "2    0  2016-11-09 20:09:03    0.0  2TzJjDVDEuAW6MR5Vuc1ug     3.0   \n",
       "3    0  2018-01-09 20:56:38    0.0  yi0R0Ugj_xUx_Nek0-_Qig     0.0   \n",
       "4    0  2018-01-30 23:07:38    0.0  11a8sVPMUFtaC7_ABRkmtw     7.0   \n",
       "\n",
       "                  user_id                                               text  \n",
       "0  hG7b0MtEbXx5QzbzE6C_VA  Total bill for this horrible service? Over $8G...  \n",
       "1  yXQM5uF2jS6es16SJzNHfg  I *adore* Travis at the Hard Rock's new Kelly ...  \n",
       "2  n6-Gk65cPZL6Uz8qRm3NYw  I have to say that this office really has it t...  \n",
       "3  dacAIZ6fTM6mqwW5uxkskg  Went in for a lunch. Steak sandwich was delici...  \n",
       "4  ssoyf2_x0EQMed6fgHeMyQ  Today was my second out of three sessions I ha...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining review.csv, & df.csv \n",
    "\n",
    "**Description**: \n",
    "\n",
    "Combining based on their *Unique Account ID's.*\n",
    "The end Product will be One DataFrame Consisting of Each Account:\n",
    "- **Name**, \n",
    "- **User_ID**,\n",
    "- **Review_ID**,\n",
    "- **Text**,\n",
    "- **That Users respective review(s)**,\n",
    "- **Interactions that Review (i.e: Cool, Funny, Useful)**  \n",
    "\n",
    "The goal of the model is to have the ability to type in the Review you are wanting to post on Yelp, and give the User the ability to Predict What type of Interaction they would potentially receive and Total Number of each interaction. The model Accuracy will be Displayed beside the Prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Layout of Columns \n",
    "final_df = review[['user_id', 'date', 'review_id', 'useful', 'funny', 'cool', 'text']]\n",
    "\n",
    "#Saving Final_df\n",
    "final_df.to_csv(index=True)\n",
    "final_df.to_csv(r'final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id       0\n",
      "date          0\n",
      "review_id     0\n",
      "useful        0\n",
      "funny         0\n",
      "cool          0\n",
      "text         28\n",
      "dtype: int64\n",
      "(6685896, 7)\n"
     ]
    }
   ],
   "source": [
    "# Checking Null Values and Shape\n",
    "pp(final_df.isna().sum())\n",
    "pp(final_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Null Values from [text] column\n",
    "final = final_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id      0\n",
      "date         0\n",
      "review_id    0\n",
      "useful       0\n",
      "funny        0\n",
      "cool         0\n",
      "text         0\n",
      "dtype: int64\n",
      "(6685868, 7)\n"
     ]
    }
   ],
   "source": [
    "# Checking Null Values and Shape\n",
    "pp(final.isna().sum())\n",
    "pp(final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Final\n",
    "final.to_csv(index=True)\n",
    "final.to_csv(r'final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>['total', 'horrible', 'service', 'crooks', 'ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>['adore', 'travis', 'hard', 'rock', 'kelly', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>['office', 'organized', 'friendly', 'phillipp'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>['went', 'lunch', 'steak', 'sandwich', 'delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ssoyf2_x0EQMed6fgHeMyQ</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>11a8sVPMUFtaC7_ABRkmtw</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>['today', 'second', 'sessions', 'paid', 'sessi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id                 date               review_id  \\\n",
       "0  hG7b0MtEbXx5QzbzE6C_VA  2013-05-07 04:34:36  Q1sbwvVQXV2734tPgoKj4Q   \n",
       "1  yXQM5uF2jS6es16SJzNHfg  2017-01-14 21:30:33  GJXCdrto3ASJOqKeVWPi6Q   \n",
       "2  n6-Gk65cPZL6Uz8qRm3NYw  2016-11-09 20:09:03  2TzJjDVDEuAW6MR5Vuc1ug   \n",
       "3  dacAIZ6fTM6mqwW5uxkskg  2018-01-09 20:56:38  yi0R0Ugj_xUx_Nek0-_Qig   \n",
       "4  ssoyf2_x0EQMed6fgHeMyQ  2018-01-30 23:07:38  11a8sVPMUFtaC7_ABRkmtw   \n",
       "\n",
       "   useful  funny cool                                               text  \\\n",
       "0     6.0    1.0    0  Total bill for this horrible service? Over $8G...   \n",
       "1     0.0    0.0    0  I *adore* Travis at the Hard Rock's new Kelly ...   \n",
       "2     3.0    0.0    0  I have to say that this office really has it t...   \n",
       "3     0.0    0.0    0  Went in for a lunch. Steak sandwich was delici...   \n",
       "4     7.0    0.0    0  Today was my second out of three sessions I ha...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['total', 'horrible', 'service', 'crooks', 'ac...  \n",
       "1  ['adore', 'travis', 'hard', 'rock', 'kelly', '...  \n",
       "2  ['office', 'organized', 'friendly', 'phillipp'...  \n",
       "3  ['went', 'lunch', 'steak', 'sandwich', 'delici...  \n",
       "4  ['today', 'second', 'sessions', 'paid', 'sessi...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_ydc1",
   "language": "python",
   "name": "conda_ydc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
