{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Up: \n",
    "Before Running the cell below, you must ensure that these have been run in Terminal **IN ORDER** : \n",
    "- conda update -n base -c defaults conda \n",
    "\n",
    "    - cd SageMaker\n",
    "    \n",
    "      - cd yelp-dataset-challenge-1-ds\n",
    "      \n",
    "         - conda env create -f environment.yml\n",
    "          \n",
    "            - source activate ydc1 \n",
    "                \n",
    "                - pip install python-decouple\n",
    "                  \n",
    "                  - pip install pprintpp\n",
    "                  \n",
    "# Spacy Installs: \n",
    "\n",
    "   - python -m spacy download en_core_web_lg\n",
    "\n",
    "        - python -m spacy link en_core_web_lg en\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/',\n",
       " 'datasets/df.csv',\n",
       " 'notebooks/',\n",
       " 'notebooks/data_cleanup.ipynb',\n",
       " 'notebooks/vectorization_exploration.ipynb',\n",
       " 'notebooks/yelp_data_initial_exploration.ipynb']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import s3\n",
    "from pprintpp import pprint as pp\n",
    "from sklearn.externals import joblib\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Load in Bucket\n",
    "bucket = s3.Bucket('yelpchallenge1')\n",
    "# Look inside the bucket.\n",
    "bucket.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT RUN #### \n",
    "### ALREADY INSTALLED ###\n",
    "\n",
    "# Only have to run this once.\n",
    "# Installs the .csv 'Locally' on SageMaker Instance\n",
    "\n",
    "#bucket.get('datasets/df.csv', 'df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/ydc1/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read-in df.csv\n",
    "df = pd.read_csv('df.csv')\n",
    "# Dropping Column\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "# Dropping all Missing / Na Values from Entire Dataframe\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stars          0\n",
      "text           0\n",
      "date           0\n",
      "total_votes    0\n",
      "tokens         0\n",
      "dtype: int64\n",
      "(6685874, 5)\n"
     ]
    }
   ],
   "source": [
    "# Checking Null Values and Shape\n",
    "print(df.isna().sum())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "def tokenize(document):\n",
    "    doc = nlp(document)\n",
    "    return [token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####TEST######\n",
    "# create mini-dataframe for testing\n",
    "# want to make sure works locally on small dataset before scaling to entire dataset/AWS\n",
    "# create variable to feed into TFIDF Vectorizer fit_transform\n",
    "# to be updated to 'text' column of main dataframe (df['text']) for vectorization in AWS\n",
    "\n",
    "#mini_df = df.head(10)\n",
    "#data = mini_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable to feed into TFIDF Vectorizer fit_transform\n",
    "# to be updated to 'text' column of main dataframe (df['text']) for vectorization in AWS\n",
    "data = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=0.025, max_df=.95, ngram_range=(1,2), stop_words= 'english')\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "    # Learn vocab and transform data into form we want\n",
    " # Passing 100,000 Rows of df['text'] through Vectorizer.   \n",
    "vect = tfidf.fit_transform(data[0:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>ask</th>\n",
       "      <th>awesome</th>\n",
       "      <th>big</th>\n",
       "      <th>clearly</th>\n",
       "      <th>come</th>\n",
       "      <th>dental</th>\n",
       "      <th>dr</th>\n",
       "      <th>end</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong make</th>\n",
       "      <th>year</th>\n",
       "      <th>year -PRON-</th>\n",
       "      <th>year add</th>\n",
       "      <th>year admit</th>\n",
       "      <th>year ago</th>\n",
       "      <th>year come</th>\n",
       "      <th>year food</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zucchini appetizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364854</td>\n",
       "      <td>0.128401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.187372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174518</td>\n",
       "      <td>0.087259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057698</td>\n",
       "      <td>0.087259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032801</td>\n",
       "      <td>0.021689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               -PRON-    ask    awesome    big    clearly      come    dental  \\\n",
       "0  0.000000  0.000000    0.0   0.000000    0.0        0.0  0.000000  0.000000   \n",
       "1  0.364854  0.128401    0.0   0.048546    0.0        0.0  0.048546  0.000000   \n",
       "2  0.187372  0.000000    0.0   0.000000    0.0        0.0  0.000000  0.174518   \n",
       "3  0.000000  0.000000    0.0   0.000000    0.0        0.0  0.000000  0.000000   \n",
       "4  0.000000  0.000000    0.0   0.000000    0.0        0.0  0.000000  0.000000   \n",
       "\n",
       "         dr       end  ...  wrong make      year  year -PRON-  year add  \\\n",
       "0  0.000000  0.000000  ...    0.000000  0.000000     0.000000       0.0   \n",
       "1  0.000000  0.048546  ...    0.000000  0.000000     0.000000       0.0   \n",
       "2  0.087259  0.000000  ...    0.000000  0.057698     0.087259       0.0   \n",
       "3  0.000000  0.000000  ...    0.000000  0.000000     0.000000       0.0   \n",
       "4  0.000000  0.000000  ...    0.032801  0.021689     0.000000       0.0   \n",
       "\n",
       "   year admit  year ago  year come  year food  zucchini  zucchini appetizer  \n",
       "0    0.000000       0.0        0.0        0.0       0.0                 0.0  \n",
       "1    0.000000       0.0        0.0        0.0       0.0                 0.0  \n",
       "2    0.000000       0.0        0.0        0.0       0.0                 0.0  \n",
       "3    0.000000       0.0        0.0        0.0       0.0                 0.0  \n",
       "4    0.032801       0.0        0.0        0.0       0.0                 0.0  \n",
       "\n",
       "[5 rows x 1410 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Feature Matrix as DataFrame\n",
    "# Get feature names to use as dataframe column headers\n",
    "dtm = pd.DataFrame(vect.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vect_1.sav']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pickling the Model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(vect, 'vect_1.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "vect = joblib.load('vect_1.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.to_csv(r'dtm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_ydc1",
   "language": "python",
   "name": "conda_ydc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
